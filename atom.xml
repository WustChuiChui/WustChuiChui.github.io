<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Wust_锤锤的blog</title>
  <subtitle>萌将王大锤</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://WustChuiChui.github.io/"/>
  <updated>2016-04-07T08:19:17.493Z</updated>
  <id>http://WustChuiChui.github.io/</id>
  
  <author>
    <name>Wust_锤锤</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>强大的随机森林分类器</title>
    <link href="http://WustChuiChui.github.io/2016/04/06/Random-forest/"/>
    <id>http://WustChuiChui.github.io/2016/04/06/Random-forest/</id>
    <published>2016-04-06T14:42:16.000Z</published>
    <updated>2016-04-07T08:19:17.493Z</updated>
    
    <content type="html">&lt;p&gt;机器学习中，随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别输出的类别的众树而定，它有着许多的有点，能很好地处理多分类问题。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;基本算法&quot;&gt;&lt;a href=&quot;#基本算法&quot; class=&quot;headerlink&quot; title=&quot;基本算法&quot;&gt;&lt;/a&gt;基本算法&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;原始训练集为N，应用bootstrap法有放回的随机抽取k个新的自助样本集，并由构建k棵决策树。每次未被抽到的样本组成了k个袋外数据；&lt;/li&gt;
&lt;li&gt;设有M个变量，在每一棵树的每个节点处随机抽取m(m&amp;lt;M)个变量，从m中选择一个最具有分辨能力的变量，变量的阈值通过检查每一个分类点确定。&lt;/li&gt;
&lt;li&gt;每棵树最大限度的生长，不做任何修剪（普通的决策树算法需要剪枝）。&lt;/li&gt;
&lt;li&gt;将生成的多棵分类树组成随机森林，用随机森林分类器对新的数据进行判断与分类，其分类结果按决策树分类器的投票决定。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;优点&quot;&gt;&lt;a href=&quot;#优点&quot; class=&quot;headerlink&quot; title=&quot;优点&quot;&gt;&lt;/a&gt;优点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;对于很多种资料，它可以产生高准确度的分类器。&lt;/li&gt;
&lt;li&gt;它可以处理大量的输入变量。&lt;/li&gt;
&lt;li&gt;可以在决定类别时，评估变量的重要性。&lt;/li&gt;
&lt;li&gt;它包含一个好方法可以估计遗失的资料，并且，如果有很大一部分的资料遗失，仍可以维持准确度。&lt;/li&gt;
&lt;li&gt;它提供一个实验方法，可以去侦测variable interactions。&lt;/li&gt;
&lt;li&gt;对于不平衡的分类资料集来说，它可以平衡误差。&lt;/li&gt;
&lt;li&gt;它计算各例中的近亲度，对于数据挖掘、侦测偏离者（outlier）和将资料视觉化非常有用。&lt;/li&gt;
&lt;li&gt;它可以延伸应用在未标记的资料上，即使用非监督式聚类方法。也可以侦测偏离者和观看资料。&lt;/li&gt;
&lt;li&gt;学习过程速度很快。&lt;/li&gt;
&lt;li&gt;能够处理很高维度的数据，并且不用做特征选择。&lt;/li&gt;
&lt;li&gt;创建随机森林的时候，对generlization error使用的是无偏估计。&lt;/li&gt;
&lt;li&gt;容易扩展到并行方法&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;缺点&quot;&gt;&lt;a href=&quot;#缺点&quot; class=&quot;headerlink&quot; title=&quot;缺点&quot;&gt;&lt;/a&gt;缺点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;在某些噪音较大的分类或回归问题上会过拟合&lt;/li&gt;
&lt;li&gt;对于有不同级别的属性的数据，级别划分较多的属性会对随机森林产生更大的影响，也就是说随机森林在这种数据上产生的属性权值是不可信的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;简要描述&quot;&gt;&lt;a href=&quot;#简要描述&quot; class=&quot;headerlink&quot; title=&quot;简要描述&quot;&gt;&lt;/a&gt;简要描述&lt;/h2&gt;&lt;p&gt;随机森林，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵之间是没有关联的，在得到森林之后，当有一个新的输入样本进入的时候，让森林中的每一棵决策树分别进行判断，对其进行分类，最后预测为被选择的最多的那一类。&lt;br&gt;建立决策树的过程中，需要注意两点：采样与完全分裂。首先是两个随机采样的过程，random forest对输入的数据进行行列的采样；这里的采样，可能存在重复的样本。假设有N个样本，那么采样的样本也为N个，在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中选择m（m&amp;lt;M）个,之后就是对采样后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面所有的样本都指向同一个分类。&lt;strong&gt; 一般很多的决策树算法都有一个很重要的步骤-剪枝，这里不需要这样做，因为之前的两个随机采样的过程保证了随机性，就算不减枝，也不会出现over-fitting。 &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 需要注意的是： &lt;/strong&gt; 每一棵决策树相对是较弱的，但是将多棵决策树结合起来就十分强大。可以这样比喻随机森林算法：每一棵决策树就是一个精通某一个窄领域的专家（从M个feature中选择m个让每一棵决策树进行学习），这样在随机森林中就有很多个精通不同领域的专家，对一个新的输入数据，可以从不同的角度去分析，最终由各方面的专家进行投票，得到最终结果。&lt;/p&gt;
&lt;h2 id=&quot;分裂特征点的选择&quot;&gt;&lt;a href=&quot;#分裂特征点的选择&quot; class=&quot;headerlink&quot; title=&quot;分裂特征点的选择&quot;&gt;&lt;/a&gt;分裂特征点的选择&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;信息增益&lt;/li&gt;
&lt;li&gt;信息增益化&lt;/li&gt;
&lt;li&gt;基尼指数&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;over-fitting的解决思路（不针对随机森林）&quot;&gt;&lt;a href=&quot;#over-fitting的解决思路（不针对随机森林）&quot; class=&quot;headerlink&quot; title=&quot;over-fitting的解决思路（不针对随机森林）&quot;&gt;&lt;/a&gt;over-fitting的解决思路（不针对随机森林）&lt;/h2&gt;&lt;p&gt;over-fitting(过拟合)指的是这样的一种学习现象：Ein很小，Eout却很大。是机器学习中比较常见的一种问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 原因： &lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用过于复杂的模型；&lt;/li&gt;
&lt;li&gt;数据噪音；&lt;/li&gt;
&lt;li&gt;有限的训练集。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt; 解决思路： &lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;假设过于复杂（excessive dvc）-&amp;gt;建立相对简单的模型；&lt;/li&gt;
&lt;li&gt;随机噪音 -&amp;gt;数据清洗，将标签错误的数据纠正或者删除；&lt;/li&gt;
&lt;li&gt;数据规模太小 -&amp;gt;收集更多的数据，或“伪造”更多数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;相关工具箱&quot;&gt;&lt;a href=&quot;#相关工具箱&quot; class=&quot;headerlink&quot; title=&quot;相关工具箱&quot;&gt;&lt;/a&gt;相关工具箱&lt;/h2&gt;&lt;p&gt;由于技术相对比较成熟，网上有大量开源的工具箱，2014年我在做视网膜层分割的时候，下载的工具箱来源于CSDN,代码语言为C/C++,另外，MATLAB也集成了相关工具箱，也可以使用MEX调用C/C++函数，python作为一门比较适合机器学习开发研究的语言，也集成了相关工具箱，感兴趣的同学可以自行下载。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习中，随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别输出的类别的众树而定，它有着许多的有点，能很好地处理多分类问题。&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Twin SVM的数学求解方法</title>
    <link href="http://WustChuiChui.github.io/2016/04/06/solve-Twin-SVM/"/>
    <id>http://WustChuiChui.github.io/2016/04/06/solve-Twin-SVM/</id>
    <published>2016-04-06T14:42:16.000Z</published>
    <updated>2016-04-08T01:04:29.860Z</updated>
    
    <content type="html">&lt;p&gt;第一篇博客已经对Twin SVM做了简单的介绍，这里主要从数学的角度去分析Twin SVM的求解思路。&lt;/p&gt;
&lt;h2 id=&quot;一、基本思想&quot;&gt;&lt;a href=&quot;#一、基本思想&quot; class=&quot;headerlink&quot; title=&quot;一、基本思想&quot;&gt;&lt;/a&gt;一、基本思想&lt;/h2&gt;&lt;p&gt;首先构造两个超平面，一个正超平面和一个负超平面，使得正负超平面尽可能地分别接近所有正类点的输入和负类点的输入，然后以这两个超平面为基础，构造决策函数；输入x距离正超平面较负超平面近时，即推断为正类；否则推断为负类。&lt;/p&gt;
&lt;h2 id=&quot;二、数学描述&quot;&gt;&lt;a href=&quot;#二、数学描述&quot; class=&quot;headerlink&quot; title=&quot;二、数学描述&quot;&gt;&lt;/a&gt;二、数学描述&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxjw1f2oiyiajyqj30jy085dh6.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Twin SVM 要求正超平面尽可能地靠近正类点，并尽可能地远离负类点；而负超平面尽可能地靠近负类点，并尽可能地远离正类点。由此，两个超平面的原始问题为：&lt;br&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/006qSkuxjw1f2oj1vyvogj30m807lmxu.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;和&lt;br&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/006qSkuxjw1f2oj3yicixj30ll06hjrz.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中，di为惩罚参数，&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxjw1f2oj6kite7j30eq01ct8r.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;目标函数第一项的作用是使正平面尽可能接近正输入；第二项和两个约束条件是使正超平面离开负输入一个距离，尽可能把负输入排斥在限定负超平面的另一侧。&lt;br&gt;它们的对偶问题分别为&lt;br&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/006qSkuxjw1f2oj8jivd9j30fa08qdgj.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxjw1f2ojab77xnj30io06x74z.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxjw1f2ojb6qjrjj30fd04rdg4.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;即得到Twin SVM的决策函数为&lt;br&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxjw1f2ojc8e0rqj30ei028mx7.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;第一篇博客已经对Twin SVM做了简单的介绍，这里主要从数学的角度去分析Twin SVM的求解思路。&lt;/p&gt;
&lt;h2 id=&quot;一、基本思想&quot;&gt;&lt;a href=&quot;#一、基本思想&quot; class=&quot;headerlink&quot; title=&quot;一、基本思想&quot;&gt;&lt;/a&gt;一、基本思想&lt;/h
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何利用Hexo在自己的博客中添加多说评论</title>
    <link href="http://WustChuiChui.github.io/2016/04/02/comments/"/>
    <id>http://WustChuiChui.github.io/2016/04/02/comments/</id>
    <published>2016-04-02T12:02:54.000Z</published>
    <updated>2016-04-02T12:50:01.014Z</updated>
    
    <content type="html">&lt;p&gt;利用github+hexo搭建自己的博客后，可以自定义搭建自己的博客，要为自己的博客添加留言功能，需要完成一下几部：&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;#一、注册自己的多说账号&lt;br&gt;在百度上搜索多说，创建自己的站点，得到一个多说的二级域名。&lt;/p&gt;
&lt;p&gt;#二、修改自己本地的配置文件&lt;br&gt;在自己的博客根目录下以文本编辑器打开_config.yml文件，添加duoshuo_shortname: 你在多说得到的二级域名。当然也可以在根目录下找到themes文件夹，选中你用的主题的配置文件_config.yml文件，将其中的duoshuo_shortname:的值赋为多说二级域名。&lt;/p&gt;
&lt;p&gt;接下来需要修改选用主题的部分js脚本内容，如果你使用的是默认的landscape主题，这时只需要修改：你的博客根目录\themes\landscape\layout_partial\article.ejs中的以下代码&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;% if (!index &amp;amp;&amp;amp; post.comments &amp;amp;&amp;amp; config.disqus_shortname)&amp;#123; %&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;section id=&amp;quot;comments&amp;quot;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;div id=&amp;quot;disqus_thread&amp;quot;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;noscript&amp;gt;Please enable JavaScript to view the &amp;lt;a href=&amp;quot;//disqus.com/?ref_noscript&amp;quot;&amp;gt;comments powered by Disqus.&amp;lt;/a&amp;gt;&amp;lt;/noscript&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;/div&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;/section&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;% &amp;#125; %&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;改为：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;% if (!index &amp;amp;&amp;amp; post.comments &amp;amp;&amp;amp; config.duoshuo_shortname)&amp;#123; %&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;section id=&amp;quot;comments&amp;quot;&amp;gt;     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;div id=&amp;quot;ds-thread&amp;quot; class=&amp;quot;ds-thread&amp;quot; data-thread-key=&amp;quot;&amp;lt;%= post.path %&amp;gt;&amp;quot; data-title=&amp;quot;&amp;lt;%= post.title %&amp;gt;&amp;quot; data-url=&amp;quot;&amp;lt;%= post.permalink %&amp;gt;&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;var duoshuoQuery = &amp;#123;short_name:&amp;quot;datoublog&amp;quot;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    (function() &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      var ds = document.createElement(&amp;apos;script&amp;apos;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     ds.type = &amp;apos;text/javascript&amp;apos;;ds.async = true;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     ds.src = (document.location.protocol == &amp;apos;https:&amp;apos; ? &amp;apos;https:&amp;apos; : &amp;apos;http:&amp;apos;) + &amp;apos;//static.duoshuo.com/embed.js&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     ds.charset = &amp;apos;UTF-8&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     (document.getElementsByTagName(&amp;apos;head&amp;apos;)[0] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      || document.getElementsByTagName(&amp;apos;body&amp;apos;)[0]).appendChild(ds);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;#125;)();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;lt;/script&amp;gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/section&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;lt;% &amp;#125; %&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果你使用的自定义主题，比如我使用的cyanstyle，需要直接在\themes\cyanstyle\layout_partial中article.ejs添加上面的部分代码。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;利用github+hexo搭建自己的博客后，可以自定义搭建自己的博客，要为自己的博客添加留言功能，需要完成一下几部：&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Twin SVM 简介</title>
    <link href="http://WustChuiChui.github.io/2016/04/01/Twin-SVM-introduction/"/>
    <id>http://WustChuiChui.github.io/2016/04/01/Twin-SVM-introduction/</id>
    <published>2016-04-01T10:37:11.000Z</published>
    <updated>2016-04-02T11:43:50.632Z</updated>
    
    <content type="html">&lt;p&gt;在写自己的第一篇博客之前，还是想先对我的导师刘小明教授表示感谢，感谢您让我有机会接触机器学习相关算法。研究Twin SVM 相关算法已经一年有余，相对于常用的SVM，Twin SVM 有着巨大的&lt;br&gt;优势，相关理论已经十分成熟，网上也有较多开源的工具箱。接下来，就让我简单地对Twin SVM做一下介绍。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;Twin-SVM-简介&quot;&gt;&lt;a href=&quot;#Twin-SVM-简介&quot; class=&quot;headerlink&quot; title=&quot;Twin SVM 简介&quot;&gt;&lt;/a&gt;Twin SVM 简介&lt;/h1&gt;&lt;h2 id=&quot;一、定义&quot;&gt;&lt;a href=&quot;#一、定义&quot; class=&quot;headerlink&quot; title=&quot;一、定义&quot;&gt;&lt;/a&gt;一、定义&lt;/h2&gt;&lt;p&gt;在介绍Twin SVM之前，先简要地介绍一下当前比较火的支持向量机(Support Vector Machine,简称SVM，它是建立在统计学习理论和最优化理论基础上的一种有效的解决分类问题的机器学习方法。双重支持向量机（Twin Support Vector Machine）是在SVM的基础上发展起来的，是利用最优化方法解决分类问题的新工具。其基本思想是构造两个非平行的超平面来代替标准的SVM的一个分划超平面，具有较好的泛化推广能力。&lt;/p&gt;
&lt;h2 id=&quot;二、起源&quot;&gt;&lt;a href=&quot;#二、起源&quot; class=&quot;headerlink&quot; title=&quot;二、起源&quot;&gt;&lt;/a&gt;二、起源&lt;/h2&gt;&lt;p&gt;SVM是由Vapnik等人提出的，在一定程度上克服了“过学习”和“维数灾难”等传统问题。它根据有限的样本信息在模型的复杂性和学习能力之间寻求最佳折衷。以求获得最好的推广能力。Twin SVM最初由Jayadeva等人于2007年针对二分类问题提出的。Twin SVM较传统的SVM运算速度更快，对大规模数据具有更好的处理能力；同时，Twin SVM 利用最大间隔思想将SVM构造的平行平面推广到更广泛的非平行平面。在大数据时代，Twin SVM 的优势会越来越明显（对比于SVM）。&lt;/p&gt;
&lt;h2 id=&quot;三、基本思想&quot;&gt;&lt;a href=&quot;#三、基本思想&quot; class=&quot;headerlink&quot; title=&quot;三、基本思想&quot;&gt;&lt;/a&gt;三、基本思想&lt;/h2&gt;&lt;p&gt;首先构造两个超平面，一个正超平面和一个负超平面，使得正负超平面尽可能地分别接近所有正类点的输入和负类点的输入，然后以这两个超平面为基础，构造决策函数；输入x距离正超平面较负超平面近时，即推断为正类；否则推断为负类。&lt;/p&gt;
&lt;h2 id=&quot;四、优势&quot;&gt;&lt;a href=&quot;#四、优势&quot; class=&quot;headerlink&quot; title=&quot;四、优势&quot;&gt;&lt;/a&gt;四、优势&lt;/h2&gt;&lt;p&gt;不同于传统的SVM基于最大间隔原则求得一个超平面从而得到决策函数，Twin SVM 需要构造两个较小的凸二次优化问题，极大地减少了训练时间；&lt;br&gt;Twin SVM较传统的SVM运算速度更快，对大规模数据具有更好的处理能力；&lt;br&gt;同时具有良好的泛化能力。&lt;/p&gt;
&lt;h2 id=&quot;五、核心要素&quot;&gt;&lt;a href=&quot;#五、核心要素&quot; class=&quot;headerlink&quot; title=&quot;五、核心要素&quot;&gt;&lt;/a&gt;五、核心要素&lt;/h2&gt;&lt;p&gt;同SVM类似，Twin SVM的三个核心的要素是：最大间隔原则，对偶理论，核函数。其中，最关键在于核函数：低维空间向量通常难以划分，解决的办法是将它们映射到高维空间，但这个办法带来的困难是计算复杂度的增加，而核函数正好巧妙地解决了这个问题；&lt;strong&gt; 即：只要选用了适当的核函数，就可以得到高维空间的分类函数。 &lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;六、数学描述&quot;&gt;&lt;a href=&quot;#六、数学描述&quot; class=&quot;headerlink&quot; title=&quot;六、数学描述&quot;&gt;&lt;/a&gt;六、数学描述&lt;/h2&gt;&lt;p&gt;设训练集为T={(x1,+1),….,(xp,+1),(X(p+1),-1),…(x(p+q),-1)},其中,x(i)∈𝑅^𝑛,i=1,…p+q。分类问题就是根据给定的训练集分别求得一对不平行的拟合超平面w*x+b=0(正负超平面分别对应一组w,b的值)。最终根据得到一组非平行的超平面对新的样本进行分类。&lt;/p&gt;
&lt;p&gt;第一篇就介绍这么多啦，相对比较基础，后续会继续介绍相关Twin求解方法和实际应用，希望对大家有所帮助。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在写自己的第一篇博客之前，还是想先对我的导师刘小明教授表示感谢，感谢您让我有机会接触机器学习相关算法。研究Twin SVM 相关算法已经一年有余，相对于常用的SVM，Twin SVM 有着巨大的&lt;br&gt;优势，相关理论已经十分成熟，网上也有较多开源的工具箱。接下来，就让我简单地对Twin SVM做一下介绍。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
