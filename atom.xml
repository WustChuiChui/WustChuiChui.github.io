<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Wust_锤锤的blog</title>
  <subtitle>萌将王大锤</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://WustChuiChui.github.io/"/>
  <updated>2016-04-14T08:58:14.130Z</updated>
  <id>http://WustChuiChui.github.io/</id>
  
  <author>
    <name>Wust_锤锤</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ID3决策树算法的实现（Python）</title>
    <link href="http://WustChuiChui.github.io/2016/04/14/achieve-ID3/"/>
    <id>http://WustChuiChui.github.io/2016/04/14/achieve-ID3/</id>
    <published>2016-04-14T08:54:29.000Z</published>
    <updated>2016-04-14T08:58:14.130Z</updated>
    
    <content type="html">&lt;p&gt;ID3算法是一种贪心算法，用来构造决策树。ID3算法起源于概念学习系统（CLS），以信息熵的下降速度为选取测试属性的标准，即在每个节点选取还尚未被用来划分的具有最高信息增益的属性作为划分标准，然后继续这个过程，直到生成的决策树能完美分类训练样例.&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;ID3决策树算法的实现（Python）&quot;&gt;&lt;a href=&quot;#ID3决策树算法的实现（Python）&quot; class=&quot;headerlink&quot; title=&quot;ID3决策树算法的实现（Python）&quot;&gt;&lt;/a&gt;ID3决策树算法的实现（Python）&lt;/h1&gt;&lt;p&gt;这里主要给出ID3算法的实现代码，关于ID3算法的介绍，可参考本人的博客&amp;gt;&lt;a href=&quot;https://wustchuichui.github.io/2016/04/14/ID3-Tree/&quot;&gt;https://wustchuichui.github.io/2016/04/14/ID3-Tree/&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;100&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;from numpy import *&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import math&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import copy&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import cPickle as pickle&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;class ID3DTree(object):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def __init__(self):     #构造方法&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.tree=&amp;#123;&amp;#125;        #生成的树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.dataSet=[]     #数据集&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.lables=[]      #标签集&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #数据导入函数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def loadDataSet(self,path,lables):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        recordlist=[]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fp=open(path,&amp;quot;rb&amp;quot;)  #读取文件内容&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        content=fp.read()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fp.close()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        rowlist=content.splitlines()     #按行转换为一维表&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        recordlist=[row.split(&amp;quot;\t&amp;quot;) for row in rowlist if row.strip()]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.dataSet=recordlist&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.lables=lables&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #执行决策函数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def train(self):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        lables=copy.deepcopy(self.lables)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.tree=self.buildTree(self.dataSet,lables)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #构建决策树，创建决策树主程序&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def buildTree(self,dataSet,lables):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        cateList=[data[-1] for data in dataSet]   #抽取源数据集中的决策标签列&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #程序终止条件1：如果classList只有一种决策标签，停止划分，返回这个决策标签&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if cateList.count(cateList[0])==len(cateList):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            return cateList[0]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #程序终止条件2：如果数据集的第一个决策标签只有一个，返回这个标签&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if len(dataSet[0])==1:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            return self.maxCate(cateList)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #核心部分&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        bestFeat=self.getBestFeat(dataSet) #返回数据集的最优特征轴&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        bestFeatLabel=lables[bestFeat]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        tree=&amp;#123;bestFeatLabel:&amp;#123;&amp;#125;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        del(lables[bestFeat])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #抽取最优特征轴的列向量&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        uniqueVals=set([data[bestFeat] for data in dataSet])  #去重&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for value in uniqueVals:          #决策树递归生长&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            subLables=lables[:]           #将删除后的特征类别集建立子类别集&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            #按最优特征列和值分隔数据集&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            splitDataset=self.splitDataset(dataSet,bestFeat,value)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            subTree=self.buildTree(splitDataset,subLables)  #构建子树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            tree[bestFeatLabel][value]=subTree&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return tree&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #计算出现次数最多的类别标签&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def maxCate(self,cateList):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        items=dict([(cateList.count(i),i) for i in cateList])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return items[max(items.keys())]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #计算最优特征&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def getBestFeat(self,dataSet):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #计算特征向量维，其中最后一列用于类别标签&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        numFeatures=len(dataSet[0])-1  #特征向量维数=行向量维数-1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        baseEntropy=self.computeEntropy(dataSet) #基础熵&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        bestInfoGain=0.0         #初始化最优的信息增益&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        bestFeature=-1           #初始化最优的特征轴&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #外循环：遍历数据集各列，计算最优特征轴&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #i为数据集列索引：取值范围0~(numFeatures-1)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for i in xrange(numFeatures):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            uniqueVals=set([data[i] for data in dataSet]) #去重&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            newEntropy=0.0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            for value in uniqueVals:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                subDataSet=self.splitDataSet(dataSet,i,value)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                prob=len(subDataSet)/float(len(dataSet))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                newEntropy+=prob*self.computeEntropy(subDataSet)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            infoGain=baseEntropy-newEntropy&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            if(infoGain&amp;gt;bestInfoGain):  #信息增益大于0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                bestInfoGain=infoGain   #用当前信息增益值替代之前的最优增益值&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                bestFeature=i           #重置最优特征为当前列&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return bestFeature&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #计算信息熵&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def computeEntropy(self,dataSet):   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        datalen=float(len(dataSet))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        cateList=[data[-1] for data in dataSet]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #得到类别为key、出现次数value的字典&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        items=dict([(i,cateList.count(i)) for i in cateList])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        infoEntropy=0.0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for key in items:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            prob=float(items[key])/datalen&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            infoEntropy-=prob*math.log(prob,2)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return infoEntropy&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #划分数据集；分隔数据集；删除特征轴所在的数据列，返回剩余的数据集&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #dataSet:数据集；axis:特征轴；value:特征轴的取值&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def splitDataSet(self,dataSet,axis,value):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        rtnList=[]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for featVec in dataSet:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            if featVec[axis]==value:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                rFeatVec=featVec[:axis]    #list操作：提取0~（axis-1）的元素&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                rFeatVec.extend(featVec[axis+1:])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                rtnList.append(rFeatVec)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return rtnList&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;ID3算法是一种贪心算法，用来构造决策树。ID3算法起源于概念学习系统（CLS），以信息熵的下降速度为选取测试属性的标准，即在每个节点选取还尚未被用来划分的具有最高信息增益的属性作为划分标准，然后继续这个过程，直到生成的决策树能完美分类训练样例.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>决策树的发展 信息熵和ID3</title>
    <link href="http://WustChuiChui.github.io/2016/04/14/ID3-Tree/"/>
    <id>http://WustChuiChui.github.io/2016/04/14/ID3-Tree/</id>
    <published>2016-04-14T05:59:20.000Z</published>
    <updated>2016-04-14T07:46:00.014Z</updated>
    
    <content type="html">&lt;p&gt;决策树算法是最早的机器学习算法之一。ID3的一个分支是分类回归决策树算法（Classification and Regression Tree,CART）。CART决策树主要用于预测分析。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;决策树的发展-信息熵和ID3&quot;&gt;&lt;a href=&quot;#决策树的发展-信息熵和ID3&quot; class=&quot;headerlink&quot; title=&quot;决策树的发展 信息熵和ID3&quot;&gt;&lt;/a&gt;决策树的发展 信息熵和ID3&lt;/h1&gt;&lt;h2 id=&quot;一、基本思想&quot;&gt;&lt;a href=&quot;#一、基本思想&quot; class=&quot;headerlink&quot; title=&quot;一、基本思想&quot;&gt;&lt;/a&gt;一、基本思想&lt;/h2&gt;&lt;p&gt;决策树的思想来源非常朴素，在程序设计中，最基本的语句条件分支结构就是if-then结构，最早的决策树就是利用这类结构分隔数据的一种分类学习方法。&lt;/p&gt;
&lt;h2 id=&quot;二、算法框架&quot;&gt;&lt;a href=&quot;#二、算法框架&quot; class=&quot;headerlink&quot; title=&quot;二、算法框架&quot;&gt;&lt;/a&gt;二、算法框架&lt;/h2&gt;&lt;p&gt;&lt;strong&gt; 1.决策树主函数 &lt;/strong&gt;&lt;br&gt;决策树主函数本质上是一个递归函数，它按某种规则生长出决策树的分支节点，并根据终止条件结束算法。它需要完成以下几个功能：&lt;br&gt;（1）输入需要分类的数据集和类别标签；&lt;br&gt;（2）根据某种分类规则得到最优化的划分特征，并创建特征的划分节点——计算最优化特征子函数；&lt;br&gt;（3）按照划分子函数的计算结果构建新的节点——划分数据集子函数；&lt;br&gt;（4）根据划分子函数的计算结果构建出新的节点，作为树生长出的新分支；&lt;br&gt;（5）检验是否符合递归的终止条件；&lt;br&gt;（6）将划分的新节点包含的数据集和类别标签作为输入，递归执行上述步骤。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 2.计算最优特征子函数 &lt;/strong&gt;&lt;br&gt;计算最优特征子函数是除了主函数外最重要的函数。&lt;strong&gt; 最优特征选择的标准上的差异性将导致不同决策树之间的差异性。 &lt;/strong&gt;&lt;br&gt;ID3的最优特征选择标准是：&lt;strong&gt; 信息增益 &lt;/strong&gt;&lt;br&gt;C4.5的最优特征选择标准是：&lt;strong&gt; 信息增益率 &lt;/strong&gt;&lt;br&gt;CART的最优特征选择标准是：&lt;strong&gt; 节点方差大小 &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 3.划分数据集函数 &lt;/strong&gt;&lt;br&gt;划分数据集函数的主要功能是分隔数据集，有的需要删除某个特征轴所在的数据列，返回剩余的数据集；有的干脆将数据一分为二等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 4.分类器 &lt;/strong&gt;&lt;br&gt;所有的机器学习都要用于分类或回归预测，决策树的分类器就是通过遍历整个决策树，使得测试数据集找到决策树中的叶子节点对应的类别标签，也就是返回的类别结果。&lt;/p&gt;
&lt;h2 id=&quot;三、信息熵&quot;&gt;&lt;a href=&quot;#三、信息熵&quot; class=&quot;headerlink&quot; title=&quot;三、信息熵&quot;&gt;&lt;/a&gt;三、信息熵&lt;/h2&gt;&lt;p&gt;熵是用来表示任何一种能量在空间中的均匀程度。能量分布得越均匀，熵越大。信息指的是对不确定性的消除。信息熵是事物不确定性的度量标准，也称为信息的单位或“测度”。信源的平均不确定性应当为单个符号不确定性的统计平均值(E),可称为信息熵，即 :&lt;br&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/006qSkuxgw1f2w8t0ea0sj30db02974c.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;假设S是s个数据样本的集合。假定类别标签具有m个不同值，定义m个不同类Ci(i=1,2,3,…m).设si是类Ci中样本数。对给定的样本分类所需要的信息熵由下式给出：&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxgw1f2w90g8dvsj30cz02haa4.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中pi是任意样本属于Ci的概率，用si/S估计。&lt;br&gt;设A具有v个不同值{a1,a2,…av}.A将S划分为v个子集{S1,S2,…,Sv}。Sj包含S中这样一些样本：他们在A上具有值aj.如果选A作测试特征，即最优划分特征，由A划分成子集的熵或期望信息由下式给出：&lt;br&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxgw1f2w9cn1nnnj30i102imxe.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在ID3决策树算法中，使用信息增益确定决策树分支的划分标准。它是决策树某个分支上整个数据集信息熵与当前节点信息熵的差值，即：&lt;br&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/006qSkuxgw1f2w9k7hwf7j30ce01aweh.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;四、ID3决策树&quot;&gt;&lt;a href=&quot;#四、ID3决策树&quot; class=&quot;headerlink&quot; title=&quot;四、ID3决策树&quot;&gt;&lt;/a&gt;四、ID3决策树&lt;/h2&gt;&lt;p&gt;ID3决策树生成过程如下：&lt;br&gt;（1）计算给定样本分类所需的信息熵；&lt;br&gt;（2）计算每个特征的信息熵；&lt;br&gt;（3）从所有的特征列中选出信息增益量最大的那个作为根节点或内部节点——划分节点，划分整列，首次递归选择列来划分。&lt;br&gt;（4）根据划分节点的不同取值来拆分数据集为若干个子集，然后删去当前的特征列，再计算剩余特征列的信息熵。如果有信息增益，就重复第二步直至划分结束。&lt;br&gt;（5）划分结束的标志为：子集中一个类别标签，停止划分。&lt;/p&gt;
&lt;h2 id=&quot;五、算法评估&quot;&gt;&lt;a href=&quot;#五、算法评估&quot; class=&quot;headerlink&quot; title=&quot;五、算法评估&quot;&gt;&lt;/a&gt;五、算法评估&lt;/h2&gt;&lt;p&gt;它以信息熵为度量标准，划分出决策树特征节点，每次优先选取信息量最多的属性，也就是使信息熵变为最小的属性，以构造一棵信息熵下降最快的决策树。&lt;br&gt;ID3存在的一些问题：&lt;br&gt;1）ID3算法的节点划分度量标准采用的是信息增益，信息增益偏向于选择特征值个数较多的特征。而取值个数较多的特征并不一定是最优的特征，所以需要改进选择属性的节点划分度量标准。&lt;br&gt;2）算法递归实现过程中要依次计算每个特征值，对于大型数据会生成比较复杂的决策树：层次和分支都很多，而其中某些分支的特征值概率很小，容易造成过拟合问题。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;决策树算法是最早的机器学习算法之一。ID3的一个分支是分类回归决策树算法（Classification and Regression Tree,CART）。CART决策树主要用于预测分析。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Python与机器学习 K近邻算法及实现</title>
    <link href="http://WustChuiChui.github.io/2016/04/13/K-Nearest-Neighbor/"/>
    <id>http://WustChuiChui.github.io/2016/04/13/K-Nearest-Neighbor/</id>
    <published>2016-04-13T02:11:04.000Z</published>
    <updated>2016-04-13T03:11:39.975Z</updated>
    
    <content type="html">&lt;p&gt;通过计算向量间的距离衡量相似度来实现分类，就是k-NN(k-Nearest Neighbor)算法，一种基于向量间相似度的分类算法。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;Python与机器学习-K近邻算法及实现&quot;&gt;&lt;a href=&quot;#Python与机器学习-K近邻算法及实现&quot; class=&quot;headerlink&quot; title=&quot;Python与机器学习 K近邻算法及实现&quot;&gt;&lt;/a&gt;Python与机器学习 K近邻算法及实现&lt;/h1&gt;&lt;h2 id=&quot;一、算法原理&quot;&gt;&lt;a href=&quot;#一、算法原理&quot; class=&quot;headerlink&quot; title=&quot;一、算法原理&quot;&gt;&lt;/a&gt;一、算法原理&lt;/h2&gt;&lt;p&gt;k-最近邻（k-Nearest Neighbor）算法是一种较简单的机器学习算法。它采用测量不同特征值之间的距离方法进行分类。它的基本思想如下：如果一个样本在特征空间中的k个最近邻的样本中的大多数都属于某一个类别，则该样本也属于这个类别。&lt;br&gt;&lt;strong&gt; 算法流程： &lt;/strong&gt;&lt;br&gt;第一阶段：确定k值（最近邻居的个数），一般为一个奇数。&lt;br&gt;第二阶段：确定距离度量公式，文本分类一般使用&lt;strong&gt; 余弦夹角 &lt;/strong&gt;进行度量。&lt;br&gt;第三阶段：统计k个样本点中各个类别的数量，根据k各样本中数量最多的样本的类别确定输入数据的类别。&lt;/p&gt;
&lt;h2 id=&quot;二、算法评估&quot;&gt;&lt;a href=&quot;#二、算法评估&quot; class=&quot;headerlink&quot; title=&quot;二、算法评估&quot;&gt;&lt;/a&gt;二、算法评估&lt;/h2&gt;&lt;p&gt;&lt;strong&gt; 优点： &lt;/strong&gt;&lt;br&gt;1.简单，易于理解，无需估计参数，无需训练；&lt;br&gt;2.适合对稀有事件进行分类；&lt;br&gt;3.特别适合于多分类问题，在此领域k-NN比SVM表现要好。&lt;br&gt;&lt;strong&gt; 缺点： &lt;/strong&gt;&lt;br&gt;1.样本不平衡时，可能会影响分类结果；&lt;br&gt;2.计算量相对较大，原因是对每一个样本，都要计算它到全体样本的距离；&lt;br&gt;3.可理解性差，无法给出类似于决策树那样的规则。&lt;/p&gt;
&lt;h2 id=&quot;三、Python实现&quot;&gt;&lt;a href=&quot;#三、Python实现&quot; class=&quot;headerlink&quot; title=&quot;三、Python实现&quot;&gt;&lt;/a&gt;三、Python实现&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;#第一阶段：导入所需的库，进行数据的初始化。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import sys&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import os&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;from numpy import *&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import numpy as np &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import operator&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;from Nbayes_lib import *&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#配准UTF-8输出环境&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;reload(sys)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sys.setdefaultencoding(&amp;apos;utf-8&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;k=3   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#第二阶段：实现夹角余弦的距离公式&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;def cosdist(vector1,voctor2):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return dot(vector1,voctor2)/(linalg.norm(vector1)*linalg.norm(voctor2))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#第三阶段：kNN实现分类器&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#测试集：testdata; 训练集：trainSet; 类别标签：listClasses; k：k个近邻数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;def classify(testdata,trainSet,listClasses,k):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    dataSetSize=trainSet.shape[0]   #样本集的行数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    distances=array(zeros(dataSetSize))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for indx in xrange(dataSetSize):   #计算测试集与训练集之间的距离：余弦夹角&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        distances[indx]=cosdist(testdata,trainSet[indx])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sortedDistIndicies=argsort(-distances)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    classCount=&amp;#123;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for i in range(k):     #获取角度最小的前k项作为参考项&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        #按排序顺序返回样本集对应的类别标签&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        voteIkabel=listClasses[sortedDistIndicies[i]]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        clssCount[voteIkabel]=classCount.get(voteIkabel,0)+1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #对分类字典按value排序&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sorted(data.iteritems(),key=operator.itemgetter(1),reverse=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #该句按字典值排序的固定用法&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sortedClassCount=sorted(classCount.iteritems(),key=operator.itemgetter(1),reverse=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return sortedClassCount[0][0]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;四、改进策略&quot;&gt;&lt;a href=&quot;#四、改进策略&quot; class=&quot;headerlink&quot; title=&quot;四、改进策略&quot;&gt;&lt;/a&gt;四、改进策略&lt;/h2&gt;&lt;p&gt;k-NN算法的改进主要分为分类效率和分类效果两个方面：&lt;br&gt;&lt;strong&gt; 分类效率： &lt;/strong&gt;事先对样本属性进行约简，删除对分类结果影响较小的属性，快速的得出待分类样本的类别。该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量较小的类域采用这种算法比较容易产生误分。&lt;br&gt;&lt;strong&gt; 分类效果： &lt;/strong&gt;采用权值的方法（和该样本距离小的邻居权值大）来改进该算法，由于不同分类的文件本身有数量上差异，因此也可以选取不同数目的最近邻居，来参考分类。&lt;/p&gt;
&lt;h2 id=&quot;五、相关工具箱&quot;&gt;&lt;a href=&quot;#五、相关工具箱&quot; class=&quot;headerlink&quot; title=&quot;五、相关工具箱&quot;&gt;&lt;/a&gt;五、相关工具箱&lt;/h2&gt;&lt;p&gt;MATLAB：MATLAN 2016版集成了机器学习和深度学习相关的工具箱，其中DeepLearnToolbox-master中包含k-N等多种算法；&lt;br&gt;Python: scikit-learn 库中有该函数的实现&lt;br&gt;C++:CSDN 上有C++版的代码实现&lt;br&gt;R语言：&amp;gt;&lt;a href=&quot;http://blog.csdn.net/liulewei/article/details/8288412&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/liulewei/article/details/8288412&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;通过计算向量间的距离衡量相似度来实现分类，就是k-NN(k-Nearest Neighbor)算法，一种基于向量间相似度的分类算法。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>二叉树的几种遍历算法及其实现（C/C++）</title>
    <link href="http://WustChuiChui.github.io/2016/04/12/visit-binary-tree/"/>
    <id>http://WustChuiChui.github.io/2016/04/12/visit-binary-tree/</id>
    <published>2016-04-12T13:41:45.000Z</published>
    <updated>2016-04-13T01:20:34.986Z</updated>
    
    <content type="html">&lt;p&gt;二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”和“右子树”。二叉树的子树有左右之分，次序不能颠倒。这里对二叉树的几种遍历算法做一下整理，供大家学习。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;二叉树的几种遍历算法及其实现（C-C-）&quot;&gt;&lt;a href=&quot;#二叉树的几种遍历算法及其实现（C-C-）&quot; class=&quot;headerlink&quot; title=&quot;二叉树的几种遍历算法及其实现（C/C++）&quot;&gt;&lt;/a&gt;二叉树的几种遍历算法及其实现（C/C++）&lt;/h1&gt;&lt;h2 id=&quot;基本结构&quot;&gt;&lt;a href=&quot;#基本结构&quot; class=&quot;headerlink&quot; title=&quot;基本结构&quot;&gt;&lt;/a&gt;基本结构&lt;/h2&gt;&lt;p&gt;二叉树一般采用链式存储结构，结构体中包括data域和两个子树的指针域，其定义如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;typedef struct BiTNode&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	int data;  //数据域&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	struct BiTNode *lchild; //左子树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	struct BiTNode *rchild; //右子树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;BiTNode,*BiTree;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;二叉树的遍历&quot;&gt;&lt;a href=&quot;#二叉树的遍历&quot; class=&quot;headerlink&quot; title=&quot;二叉树的遍历&quot;&gt;&lt;/a&gt;二叉树的遍历&lt;/h2&gt;&lt;p&gt;二叉树的遍历，指的是按照一定的规则和顺序走遍二叉树的所有结点，使得每个节点都被访问一次，而且只被访问一次。&lt;br&gt;基本的遍历方法有先序、中序和后序遍历算法，并且都有递归和非递归之分。这三种方法的递归算法实现如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;//先序遍历&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void PreOrder(BiTree T)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(T!=NULL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    	Visit(T);    //Visit(T)为访问当前节点的操作，如输出该节点的值等&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    	PreOrder(T-&amp;gt;lchild); //访问左子树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    	PreOrder(T-&amp;gt;rchild); //访问右子树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//中序遍历&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void InOrder(BiTree T)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	if(T!=NULL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		InOrder(T-&amp;gt;lchild);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		Visit(T);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		InOrder(T-&amp;gt;rchild);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//后序遍历&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void PostOrder(BiTree T)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	if(T!=NULL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		PostOrder(T-&amp;gt;lchild);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		PostOrder(T-&amp;gt;rchild);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		Visit(T);		&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;对应地，给出以上算法的非递归算法：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 先序遍历： &lt;/strong&gt;&lt;br&gt;访问T-&amp;gt;data后，将T入栈，遍历左子树；遍历完左子树返回时，栈顶元素为T,出栈，再先序遍历T的右子树&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void PreOrder(BiTree T)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	stack&amp;lt;BiTree&amp;gt; stack;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	//定义一个指针，用来遍历二叉树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	BiTree p=T;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	//栈不为空或者p不为空时循环&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	while(p||!stack.empty())&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		if(p!=NULL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			//当前节点入栈&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			stack.push(p);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			Visit(p);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			//遍历左子树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			p=p-&amp;gt;lchild;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		else&amp;#123;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			p=stack.top();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			stack.pop();  //出栈&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			p=p-&amp;gt;rchild;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;	&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 中序遍历 &lt;/strong&gt;&lt;br&gt;先将T（根节点）入栈，遍历左子树；遍历完左子树返回时，出栈，访问T-&amp;gt;data,出栈，再先序遍历T的右子树&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void InOrder(BiTree T)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	stack&amp;lt;BiTree&amp;gt; stack;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	//定义一个遍历二叉树的指针&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	BiTree p=T;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	//栈不为空或者p不为空时循环&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	while(p|| !stack.empty())&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		if(p!=NULL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			stack.push(p); //入栈&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			p=p-&amp;gt;lchild;   //遍历左子树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		else&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			//出栈，访问根节点&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			p=stack.top();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			Visit(p);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			stack.pop();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			//访问右子树&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			p=p-&amp;gt;rchild;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 后序遍历 &lt;/strong&gt;&lt;br&gt;T为要遍历树的根指针，后序遍历要求先遍历完左右子树，再访问根结点。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;//后序遍历(非递归)  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;typedef struct BiTNodePost&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    BiTree biTree;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    char tag;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;BiTNodePost,*BiTreePost;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void PostOrder2(BiTree T)&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    stack&amp;lt;BiTreePost&amp;gt; stack;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    //p是遍历指针  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    BiTree p = T;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    BiTreePost BT;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    //栈不空或者p不空时循环  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while(p != NULL || !stack.empty())&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        //遍历左子树  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(p != NULL)&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            BT = (BiTreePost)malloc(sizeof(BiTNodePost));  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            BT-&amp;gt;biTree = p;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            //访问过左子树  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            BT-&amp;gt;tag = &amp;apos;L&amp;apos;;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            stack.push(BT);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            p = p-&amp;gt;lchild;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        //左右子树访问完毕访问根节点  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(!stack.empty() &amp;amp;&amp;amp; (stack.top())-&amp;gt;tag == &amp;apos;R&amp;apos;)&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            BT = stack.top();  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            //退栈  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            stack.pop();  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            BT-&amp;gt;biTree;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            printf(&amp;quot;%c &amp;quot;,BT-&amp;gt;biTree-&amp;gt;data);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        //遍历右子树  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(!stack.empty())&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            BT = stack.top();  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            //访问过右子树  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            BT-&amp;gt;tag = &amp;apos;R&amp;apos;;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            p = BT-&amp;gt;biTree;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            p = p-&amp;gt;rchild;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 广度优先（层次遍历）算法和深度优先遍历 &lt;/strong&gt;&lt;br&gt;除了上述几种遍历算法之外(从本质上讲，先序、中序、后序遍历都属于深度优先遍历)，还有广度优先算法和深度优先遍历，这里给出这两个算法的实现&lt;br&gt;&lt;strong&gt; 广度优先 &lt;/strong&gt;&lt;br&gt;思路：从顶向下，从左至右的顺序来逐层访问每个结点，这里需要用到的存储结构为&lt;strong&gt; 队列 &lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void LevelOrder(BiTree T)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	BiTree p=T;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	queue&amp;lt;BiTree&amp;gt; queue;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	//根结点入队&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	queue.push(p);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	//队列不为空时循环&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	while(!queue.empty())&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		//对头元素出列&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		p=queue.front();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		//访问p指向的结点&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		Visit(p);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		queue.pop();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		if(p-&amp;gt;lchild!=NULL)&amp;#123; //左子树不为空，将左子树入队&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			queue.push(p-&amp;gt;lchild);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		if(p-&amp;gt;rchild!=NULL)&amp;#123;  //右子树不为空，将右子树入队&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			queue.push(p-&amp;gt;rchild);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 深度优先 &lt;/strong&gt;&lt;br&gt;思路：先遍历根结点，接着遍历左子树，最后遍历右子树，这里借助&lt;strong&gt; 栈 &lt;/strong&gt; 来实现深度优先遍历&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void DepthOrder(BiTree T)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	stack&amp;lt;BiTree&amp;gt; stack;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	BiTree p=T;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	stack.push(p);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	while(!stack.empty())&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		p=stack.top();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		Visit(p);   //遍历根结点&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		stack.pop(); //出栈&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		if(p-&amp;gt;rchild)&amp;#123; //右子树入栈&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			stack.push(p-&amp;gt;rchild);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		if(p-&amp;gt;lchild)&amp;#123;  //左子树入栈&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			stack.push(p-&amp;gt;lchild);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”和“右子树”。二叉树的子树有左右之分，次序不能颠倒。这里对二叉树的几种遍历算法做一下整理，供大家学习。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Python与机器学习 贝叶斯算法</title>
    <link href="http://WustChuiChui.github.io/2016/04/12/bayes/"/>
    <id>http://WustChuiChui.github.io/2016/04/12/bayes/</id>
    <published>2016-04-12T10:05:02.000Z</published>
    <updated>2016-04-12T12:52:55.270Z</updated>
    
    <content type="html">&lt;p&gt;朴素贝叶斯分类时一种十分简单的分类算法，称其朴素是因为其思想基础的简单性，对文本分类而言，它认为词袋中的两两词之间的关系是相互独立的，即一个对象的特征向量中每个维度都是相互独立的。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;Python与机器学习-贝叶斯算法&quot;&gt;&lt;a href=&quot;#Python与机器学习-贝叶斯算法&quot; class=&quot;headerlink&quot; title=&quot;Python与机器学习 贝叶斯算法&quot;&gt;&lt;/a&gt;Python与机器学习 贝叶斯算法&lt;/h1&gt;&lt;h2 id=&quot;一、定义&quot;&gt;&lt;a href=&quot;#一、定义&quot; class=&quot;headerlink&quot; title=&quot;一、定义&quot;&gt;&lt;/a&gt;一、定义&lt;/h2&gt;&lt;p&gt;(1)设x={a1,a2,…,am}为一个待分类项，而每个a为x的一个特征属性;&lt;br&gt;(2)有类别集合C={y1,y2,…,yn};&lt;br&gt;(3)计算P(y1|x),P(y2|x),…,P(yn|x);&lt;br&gt;(4)如果P(yk|x)=max{P(y1|x),P(y2|x),…,P(yn|x)},则x属于yk。&lt;/p&gt;
&lt;p&gt;上述定义给出了对x样本进行分类的准则，分类的关键是计算各个条件概率。可以按以下步骤计算。&lt;br&gt;(1)找到一个已知分类的待分类项集合，也就是训练集；&lt;br&gt;(2)统计得到在各类别下各个特征属性的条件概率估计；&lt;br&gt;(3)如果各个特征属性是条件独立的(或者假设它们是相互独立的)，则根据贝叶斯定义有如下推论：&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxgw1f2u3ez8ww3j30qk02mq3g.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;二、分类流程&quot;&gt;&lt;a href=&quot;#二、分类流程&quot; class=&quot;headerlink&quot; title=&quot;二、分类流程&quot;&gt;&lt;/a&gt;二、分类流程&lt;/h2&gt;&lt;p&gt;(1)训练数据生成训练样本集：TF-IDF&lt;br&gt;(2)对每个类别计算P(yi)&lt;br&gt;(3)对每个特征属性计算所有划分的条件概率&lt;br&gt;(4)对每个类别计算P(x|yi)P(yi)&lt;br&gt;(5)以(x|yi)P(yi)的最大项判断x的所属类别&lt;/p&gt;
&lt;h2 id=&quot;三、算法实现&quot;&gt;&lt;a href=&quot;#三、算法实现&quot; class=&quot;headerlink&quot; title=&quot;三、算法实现&quot;&gt;&lt;/a&gt;三、算法实现&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;82&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;def loadDataSet():&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    postingList=[[&amp;apos;my&amp;apos;,&amp;apos;dog&amp;apos;,&amp;apos;has&amp;apos;,&amp;apos;flea&amp;apos;,&amp;apos;poblems&amp;apos;,&amp;apos;help&amp;apos;,&amp;apos;please&amp;apos;],[&amp;apos;maybe&amp;apos;,&amp;apos;not&amp;apos;,&amp;apos;take&amp;apos;,&amp;apos;him&amp;apos;,&amp;apos;to&amp;apos;,&amp;apos;dog&amp;apos;,&amp;apos;park&amp;apos;,&amp;apos;stupid&amp;apos;],[&amp;apos;my&amp;apos;,&amp;apos;dalmation&amp;apos;,&amp;apos;is&amp;apos;,&amp;apos;so&amp;apos;,&amp;apos;cute&amp;apos;,&amp;apos;I&amp;apos;,&amp;apos;love&amp;apos;,&amp;apos;him&amp;apos;,&amp;apos;my&amp;apos;],[&amp;apos;stop&amp;apos;,&amp;apos;posting&amp;apos;,&amp;apos;stupid&amp;apos;,&amp;apos;worthless&amp;apos;,&amp;apos;garbage&amp;apos;],[&amp;apos;mr&amp;apos;,&amp;apos;licks&amp;apos;,&amp;apos;ate&amp;apos;,&amp;apos;my&amp;apos;,&amp;apos;steak&amp;apos;,&amp;apos;how&amp;apos;,&amp;apos;to&amp;apos;,&amp;apos;stop&amp;apos;,&amp;apos;to&amp;apos;,&amp;apos;stop&amp;apos;,&amp;apos;him&amp;apos;],[&amp;apos;quit&amp;apos;,&amp;apos;buying&amp;apos;,&amp;apos;worthles&amp;apos;,&amp;apos;dog&amp;apos;,&amp;apos;food&amp;apos;,&amp;apos;stupid&amp;apos;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    classVec=[0,1,0,1,0,1]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return postingList,classVec&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #这里postingList,classVec分别为训练集和对应的分类&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #编写一个bayes算法类，实现该算法&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #默认构造方法&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;class NBayes(object):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def __init__(self):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.vocabulary=[]             #词典&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.idf=0                     #词典的IDF权值向量&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.tf=0                      #训练集中的权值矩阵&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.tdm=0                     #P(x|yi)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.Pcates=&amp;#123;&amp;#125;                 #P(yi)是一个类别字典&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.lables=[]                 #对应每个文本的分类，是一个外部导入的列表&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.doclength=0               #训练集文本数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.vocablen=0                #词典词长&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.testset=0                 #测试集&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #导入和训练集数据，生成算法必需的参数和数据结构&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def train_set(self,trainset,classVec):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.cate_prob(classVec)      #计算每个分类在数据集中的概率P(yi)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.doclength=len(trainset)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        tempset=set()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        [tempset.add(word) for doc i trainset for word in doc] #生成词典&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.vocabulary=list(tempset)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.vocablen=len(self.vocabulary)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.calc_wordfreq(trainset)    #计算词频数据集&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.built_tdm()                #按分类累计向量空间的每维值P(x|yi)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #cate_prob函数,计算在数据集中每个分类的概率P(yi)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def cate_prob(self,classVec):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.lables=classVec&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        labletemps=set(self.lables) #全部分类&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for labletemp in labletemps:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            self.lables.count(labletemp)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            self.Pcates[labletemp]=float(self.lables.count(labletemp))/float(len(self.lables))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #calc_wordfreq函数，生成普通的词频向量&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def calc_wordfreq(self,trainset):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.idf=np.zeros([1,self.vocablen])   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.tf=np.zeros(self.doclength,self.vocablen)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for indx in xrange(self.doclength):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            for word in trainset[indx]:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                self.tf[indx,self.vocabulary.index(word)]+=1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            for signleword in set(trainset[indx]):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                self.idf[0,self.vocabulary.index(signleword)]+=1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #built_tdm函数，按分类累计计算向量空间的每维值&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def built_tdm(self):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.tdm=np.zeros([len(self.Pcates),self.vocablen])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        sumlist=np.zeros([len(self.Pcates),1])    #统计每个分类的总值&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for indx in xrange(self.doclength):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            #将同一类别的词向量空间值相加&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            self.tdm[self.lables[indx]]+=self.tf[indx]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            #统计每个分类的总值，它为一个标量&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            sumlist[self.lables[indx]]=np.sum(self.tdm[self.lables[indx]])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.tdm=self.tdm/sumlist&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #map2vocab函数，将测试集映射到当前词典&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def map2vovocab(self,testdata):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.testdata=np.zeros([1,self.vocablen])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for word in testdata:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            self.testdata[0,self.vocabulary.index(word)]+=1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    #predict函数，预测分类结果，输出预测的分类类别&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    def predict(self,testdata):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if np.shape(testdata)[1]!=self.vocablen:     #测试集长度与词典长度不相等，则退出&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            print &amp;quot;Error input&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            exit(0)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        predvalue=0  #初始化类别概率&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        predclass=&amp;quot;&amp;quot; #初始化类别名称&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        for tdm_vect,keyclass in zip(self.tdm,self.Pcates):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            temp=np.sum(testset*tdm_vect*self.Pcates[keyclass])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            if temp&amp;gt;predvalue:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                predvalue=temp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                predclass=keyclass&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return predclass&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;朴素贝叶斯分类时一种十分简单的分类算法，称其朴素是因为其思想基础的简单性，对文本分类而言，它认为词袋中的两两词之间的关系是相互独立的，即一个对象的特征向量中每个维度都是相互独立的。&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>调整数组顺序使奇数位于偶数前面</title>
    <link href="http://WustChuiChui.github.io/2016/04/12/ReorderArray/"/>
    <id>http://WustChuiChui.github.io/2016/04/12/ReorderArray/</id>
    <published>2016-04-12T07:53:05.000Z</published>
    <updated>2016-04-12T09:33:39.663Z</updated>
    
    <content type="html">&lt;p&gt;问题描述：输入一个整数数组，实现一个函数调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;调整数组顺序使奇数位于偶数前面&quot;&gt;&lt;a href=&quot;#调整数组顺序使奇数位于偶数前面&quot; class=&quot;headerlink&quot; title=&quot;调整数组顺序使奇数位于偶数前面&quot;&gt;&lt;/a&gt;调整数组顺序使奇数位于偶数前面&lt;/h1&gt;&lt;p&gt;一种基础的思路：先不考虑时间复杂度，从开开始遍历数组，当当前位置为偶数时，将位于该元素后面的数字整体向前移动一位，同时将该节点的数字放在数组的最后位置，每遇到一个偶数需要移动O(n)个数字，时间复杂度为O(n2).&lt;/p&gt;
&lt;p&gt;现给出另一种思路，在扫描的过程中，如果发现有偶数在奇数的前面，则交换他们的位置，交换之后就符合要求了。基于上述分析，给出如下代码：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void ReorderOddEven(int *pData,int length)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(pData==NULL ||length==0)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int *pBegin=pData;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int *pEnd=pData+length-1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while(pBegin&amp;lt;pEnd)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(pBegin&amp;lt;pEnd &amp;amp;&amp;amp; (*pBegin &amp;amp; ox1)!=0)&amp;#123;  //找到第一个偶数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                 pBegin++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(pBegin&amp;lt;pEnd &amp;amp;&amp;amp; (*pEnd &amp;amp; ox1)==0)&amp;#123;     //找到第一个奇数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            eEnd--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     if(pBegin&amp;lt;pEnd)&amp;#123;       //交换奇数和偶数的位置&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int temp=*pBegin;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        *pBegin=*pEnd;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        *pEnd=temp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;现在如果要对上述算法进行扩展，比如：将题目简单的修改一下，将数组按大小分成两部分？将负数放在前面，正数放在后面？为了将代码进一步抽象，可以给出一个模式，修改函数ReorderOddEven中的判断标准，其他的逻辑框架不需要改动。有以下代码：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void ReorderOddEven(int *pData,int length,bool (*func)(int))&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(pData==NULL ||length==0)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int *pBegin=pData;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int *pEnd=pData+length-1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while(pBegin&amp;lt;pEnd)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(pBegin&amp;lt;pEnd &amp;amp;&amp;amp; !func(*pBegin))&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                 pBegin++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(pBegin&amp;lt;pEnd &amp;amp;&amp;amp; func(*pEnd))&amp;#123;     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            eEnd--;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     if(pBegin&amp;lt;pEnd)&amp;#123;       &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int temp=*pBegin;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        *pBegin=*pEnd;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        *pEnd=temp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bool isEven(int n)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return (n &amp;amp; 1)==0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;另外对给出的第一个算法，这里在实现题目要求时，奇偶数的相对顺序发生了变化，如果要使得在重排后奇偶数的相对顺序不变。可以借用栈或队列等容器来实现，当然，这意味着额外的内存开销，最差的情况为O(n),其代码如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void reOrderOddEven(vector&amp;lt;int&amp;gt; &amp;amp;array) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      if(array.size()&amp;lt;=0)            //异常处理&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;          return;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      vector&amp;lt;int&amp;gt; odds,evens;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      unsigned int i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      for(i=0;i&amp;lt;array.size();i++)&amp;#123;   //分别将奇数和偶数存入一个vector容器中&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;          if((array[i]&amp;amp;0x1)!=0)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             odds.push_back(array[i]);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;          if((array[i]&amp;amp;0x1)==0)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             evens.push_back(array[i]);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      for(i=0;i&amp;lt;odds.size();i++)   //将奇数和偶数分别存入array中&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;          array[i]=odds[i];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      int k=i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      for(i=0;i&amp;lt;evens.size();i++)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;          array[k++]=evens[i];        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;问题描述：输入一个整数数组，实现一个函数调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>几种从尾到头输出链表的算法比较</title>
    <link href="http://WustChuiChui.github.io/2016/04/12/Resert-print-list/"/>
    <id>http://WustChuiChui.github.io/2016/04/12/Resert-print-list/</id>
    <published>2016-04-12T01:52:50.000Z</published>
    <updated>2016-04-12T02:28:00.463Z</updated>
    
    <content type="html">&lt;p&gt;链表是一个是一种动态的线性结构，在创建链表时，无需知道链表的长度，每插入一个结点时，动态地为其分配内存，在输出链表时（单向链表），一般可沿着头指针逐步遍历所有节点，然而，要从尾到头遍历链表，可有以下几种思路：&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;几种从尾到头输出链表的算法比较&quot;&gt;&lt;a href=&quot;#几种从尾到头输出链表的算法比较&quot; class=&quot;headerlink&quot; title=&quot;几种从尾到头输出链表的算法比较&quot;&gt;&lt;/a&gt;几种从尾到头输出链表的算法比较&lt;/h1&gt;&lt;h2 id=&quot;基本思路&quot;&gt;&lt;a href=&quot;#基本思路&quot; class=&quot;headerlink&quot; title=&quot;基本思路&quot;&gt;&lt;/a&gt;基本思路&lt;/h2&gt;&lt;p&gt;在不破坏链表结构的前提下，对链表进行逆序输出，首先想到的应该是栈这样的一个结构，下面给出一个用栈实现的输出算法：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;//链表数据结构&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;struct ListNode &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int val;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        struct ListNode *next;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ListNode(int x) :&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             val(x), next(NULL) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//利用栈结构对链表进行从尾到头输出&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void printListFromTailToHead(ListNode* head)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    stack&amp;lt;ListNode&amp;gt; nodes;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ListNode* pNode=head;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while(pNode!=NULL)&amp;#123;  //依次入栈&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        nodes.push(pNode);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        pNode=pNode-&amp;gt;next;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    //出栈输出结构即可&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while(!nodes.empty())&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        pNode=nodes.top();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        cout&amp;lt;&amp;lt; pNode-&amp;gt;val &amp;lt;&amp;lt;endl;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        nodes.pop();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;由于递归在本质上就是一个栈结构，既然可以利用栈实现该算法，则利用递归也可以实现，本算法的递归算法如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void printListFromTailToHead(ListNode* head)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(head !=NULL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(head-&amp;gt;next!=NULL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;           printListFromTailToHead(head-&amp;gt;next);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        cout&amp;lt;&amp;lt; head-&amp;gt;val &amp;lt;&amp;lt; endl;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;以上两种算法都可实现题目要求，但有时我们希望将输出作为一个函数返回值，方便以后对其进行调用，可对以上算法稍做修改即可：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;vector&amp;lt;int&amp;gt; printListFromTailToHead(struct ListNode* head) &amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    stack&amp;lt;int&amp;gt; vestack;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    vector&amp;lt;int&amp;gt; ret;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while (head != NULL)&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vestack.push(head-&amp;gt;val);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        head = head-&amp;gt;next;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    while (!vestack.empty())&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int val = vestack.top();  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ret.push_back(val);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vestack.pop();  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return ret;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;递归算法实现&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;vector&amp;lt;int&amp;gt; printListFromTailToHead(struct ListNode* head)  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    vector&amp;lt;int&amp;gt; ret;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if (NULL != head)&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if (NULL != head-&amp;gt;next)&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            printListFromTailToHead(head-&amp;gt;next);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ret.push_back(head-&amp;gt;val);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return ret;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;现在可以有效从头到尾输出链表，并将结果存在一个vector结构中，但这里仍然存在一个严重的问题：&lt;br&gt;&lt;strong&gt; 在利用递归实现该算法时，当链表的长度较长时，会出现栈溢出的问题，而递归本质上也是一种栈结构，所有上述四种方法可能都存在这样的隐患。 &lt;/strong&gt; 考虑到上述问题，既然利用vector对其进行存储，不妨在顺序遍历链表时依次将当前节点的val值插入到vector中。其实现代码如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;vector&amp;lt;int&amp;gt; printListFromTailToHead(struct ListNode* head) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        vector&amp;lt;int&amp;gt; result;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ListNode* p=head;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while(p)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        result.insert(result.begin(),p-&amp;gt;val);  //依次插入当前节点的值&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        p=p-&amp;gt;next;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        return result;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;链表是一个是一种动态的线性结构，在创建链表时，无需知道链表的长度，每插入一个结点时，动态地为其分配内存，在输出链表时（单向链表），一般可沿着头指针逐步遍历所有节点，然而，要从尾到头遍历链表，可有以下几种思路：&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>那些年，我们一起写过的快排</title>
    <link href="http://WustChuiChui.github.io/2016/04/10/quick-sort/"/>
    <id>http://WustChuiChui.github.io/2016/04/10/quick-sort/</id>
    <published>2016-04-10T14:14:25.000Z</published>
    <updated>2016-04-10T14:48:23.475Z</updated>
    
    <content type="html">&lt;p&gt;在几种常用的排序算法中，快速排序总体的平均效率是最优的，这里对快速排序给出C++版的代码，希望大家相互学习。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;那些年，我们一起写过的快排&quot;&gt;&lt;a href=&quot;#那些年，我们一起写过的快排&quot; class=&quot;headerlink&quot; title=&quot;那些年，我们一起写过的快排&quot;&gt;&lt;/a&gt;那些年，我们一起写过的快排&lt;/h1&gt;&lt;h2 id=&quot;一、基本思路&quot;&gt;&lt;a href=&quot;#一、基本思路&quot; class=&quot;headerlink&quot; title=&quot;一、基本思路&quot;&gt;&lt;/a&gt;一、基本思路&lt;/h2&gt;&lt;p&gt;通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。&lt;br&gt;快速排序是一种&lt;strong&gt; 不稳定 &lt;/strong&gt;的排序算法，也就是说，多个相同的值的相对位置也许会在算法结束时产生变动。&lt;/p&gt;
&lt;h2 id=&quot;二、算法分析&quot;&gt;&lt;a href=&quot;#二、算法分析&quot; class=&quot;headerlink&quot; title=&quot;二、算法分析&quot;&gt;&lt;/a&gt;二、算法分析&lt;/h2&gt;&lt;p&gt;实现快速排序算法的关键在于先在数组中选择一个数字，接下来把数组中的数字分为两个部分，其中，比关键字小的数字移到数组的左边，比关键字大的数字移到数组的右边。&lt;/p&gt;
&lt;h2 id=&quot;三、相关代码实现&quot;&gt;&lt;a href=&quot;#三、相关代码实现&quot; class=&quot;headerlink&quot; title=&quot;三、相关代码实现&quot;&gt;&lt;/a&gt;三、相关代码实现&lt;/h2&gt;&lt;p&gt;先看数据结构中给出的基本算法代码：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;void QuickSort(int s[], int l, int r)  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if (l&amp;lt; r)  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#123;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        int i = l, j = r, x = s[l];      //以第一个数为参考基准&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        while (i &amp;lt; j)  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            while(i &amp;lt; j &amp;amp;&amp;amp; s[j]&amp;gt;= x) // 从右向左找第一个小于x的数  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                j--;   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            if(i &amp;lt; j)  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                s[i++] = s[j];  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            while(i &amp;lt; j &amp;amp;&amp;amp; s[i]&amp;lt; x) // 从左向右找第一个大于等于x的数  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                i++;   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            if(i &amp;lt; j)  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                s[j--] = s[i];  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        s[i] = x;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        QuickSort(s, l, i - 1); // 递归调用  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        QuickSort(s, i + 1, r);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里给出另一个版本的快速排序算法:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;int Partition(int data[],int length,int start,int end)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    //定义的一个函数，在数组DATA中选择一个数字，将数组中小于关键字的&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    //部分全放在关键字的左侧，大于关键字的部分放在右侧，返回关键字的索引&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    //参数异常处理&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(data==NULL || length&amp;lt;0 || start&amp;lt;0 || end&amp;gt;=length)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        throw new std:exception(&amp;quot;参数输入非法!&amp;quot;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int index=RandomInrange(start,end);   //在start 和end 直接随机取一个值&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    //data[index]作为关键字，先将其放在最后&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Swap(&amp;amp;data[index],&amp;amp;data[end]);    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int small=start-1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    for(index=start;index&amp;lt;end;++index)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     if(data[index]&amp;lt;data[end])&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ++small;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if(small!=index)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        Swap(&amp;amp;data[index],&amp;amp;data[small]);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ++small;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Swap(&amp;amp;data[small],&amp;amp;data[end]);   //最终small的位置即对应为关键字的位置&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return small; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;void QuickSort(int data[],int length,int start,int end)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if(start==end)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     return ;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     //将数组分成两个部分，index前面的数字都比data[index]小，后面的数字都大于或等于data[index]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      int index=Partition(data,length,start,end); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      if(index&amp;gt;start)      //递归&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      QuickSort(data,length,start,index-1);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      if(index&amp;lt;end)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      QuickSort(data,length,index+1,end);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;四、两种算法的比较&quot;&gt;&lt;a href=&quot;#四、两种算法的比较&quot; class=&quot;headerlink&quot; title=&quot;四、两种算法的比较&quot;&gt;&lt;/a&gt;四、两种算法的比较&lt;/h2&gt;&lt;p&gt;1、这里给出的代码在选取参考数字时，使用的随机选取知道方法，而前者是直接使用第一数字作为参考；&lt;br&gt;2、后面的代码在输入参数出现异常时能正确给出响应提示，因而更加鲁棒。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在几种常用的排序算法中，快速排序总体的平均效率是最优的，这里对快速排序给出C++版的代码，希望大家相互学习。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Python与机器学习基础 之数据可视化</title>
    <link href="http://WustChuiChui.github.io/2016/04/09/data-visualization/"/>
    <id>http://WustChuiChui.github.io/2016/04/09/data-visualization/</id>
    <published>2016-04-09T14:30:43.000Z</published>
    <updated>2016-04-10T05:10:53.477Z</updated>
    
    <content type="html">&lt;p&gt;机器学习中常常会用到大量的数据表，对数据进行可视化有助于对数据进行分析，这里主要介绍几种常用的数据可视化方向，包括表等线性结构、图等网络结构的可视化方法。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;Python与机器学习基础-之数据可视化&quot;&gt;&lt;a href=&quot;#Python与机器学习基础-之数据可视化&quot; class=&quot;headerlink&quot; title=&quot;Python与机器学习基础 之数据可视化&quot;&gt;&lt;/a&gt;Python与机器学习基础 之数据可视化&lt;/h1&gt;&lt;h2 id=&quot;一、表与线性结构的可视化&quot;&gt;&lt;a href=&quot;#一、表与线性结构的可视化&quot; class=&quot;headerlink&quot; title=&quot;一、表与线性结构的可视化&quot;&gt;&lt;/a&gt;一、表与线性结构的可视化&lt;/h2&gt;&lt;p&gt;Python提供了4种容器结构——list、dict、set、tuple来装载数据，其中线性结构包括两种：list和tuple。因为tuple是只读结构，用于最常用的外部生成器生成的数据，所以&lt;strong&gt; 最常用的线性结构是list &lt;/strong&gt;。NumPy的矩阵结构可在Matplotlib中实现可视化。例：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;import numpy as np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#曲线数据加入噪声&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;X=np.linspace(-5,5,200)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Y=np.sin(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;yn=Y+np.random.rand(1,len(Y))*1.5    #噪声&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#绘图&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;fig=plt.figure()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ax=fig.add_subplot(111)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ax.scatter(X,yn,c=&amp;apos;blue&amp;apos;,marker=&amp;apos;o&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ax.plot(X,Y+0.75,&amp;apos;r&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;其输出结果为：&lt;br&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxjw1f2qtxgvvhcj30ay07ct9h.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;二、图等网络结构的可视化&quot;&gt;&lt;a href=&quot;#二、图等网络结构的可视化&quot; class=&quot;headerlink&quot; title=&quot;二、图等网络结构的可视化&quot;&gt;&lt;/a&gt;二、图等网络结构的可视化&lt;/h2&gt;&lt;p&gt;图和网络结构是神经网络中重要的数据结构，一般用dict和list进行存储，使用NumPy中的矩阵结构存储点坐标；弧的坐标使用距离计算公式。例：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;from numpy import *&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#import treePlotter as tp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#配置UTF-8输出环境&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#reload(sys)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#sys.setdefaultencoding(&amp;apos;utf-8&amp;apos;) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dist=mat([[0.1,0.1],[0.9,0.5],[0.9,0.1],[0.45,0.9],[0.9,0.8],[0.7,0.9],[0.1,0.45],[0.45,0.1]])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;m,n=shape(dist)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;fig=plt.figure()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ax=fig.add_subplot(111)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ax.scatter(dist.T[0],dist.T[1],c=&amp;apos;blue&amp;apos;,marker=&amp;apos;o&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;for point in dist.tolist():&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    plt.annotate(&amp;quot;(&amp;quot;+str(point[0])+&amp;quot;,&amp;quot;+str(point[1])+&amp;quot;)&amp;quot;,xy=(point[0],point[1]))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;xlist=[]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ylist=[]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;for px,py in zip(dist.T.tolist()[0],dist.T.tolist()[1]):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    xlist=append(px)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ylist=append(py)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ax.plot(xlist,ylist,&amp;apos;r&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;三、树等分支结构的可视化&quot;&gt;&lt;a href=&quot;#三、树等分支结构的可视化&quot; class=&quot;headerlink&quot; title=&quot;三、树等分支结构的可视化&quot;&gt;&lt;/a&gt;三、树等分支结构的可视化&lt;/h2&gt;&lt;p&gt;树是一种非线性的结构，一般用来分类树算法，Python使用dict字典型数据实现存储。Matplotlib没有提供专门绘制树的API.Peter Harrington提供了一个简单绘制树的模块。例：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;import numpy as np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import treePlotter as tp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;reload(sys)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sys.setdefaultencoding(&amp;apos;utf-8&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;myTree=&amp;#123;&amp;apos;root&amp;apos;:&amp;#123;0:&amp;apos;leaf node&amp;apos;,1:&amp;#123;&amp;apos;level 2&amp;apos;:&amp;#123;0:&amp;apos;leaf node&amp;apos;,1:&amp;apos;leaf node&amp;apos;&amp;#125;&amp;#125;,2:&amp;#123;&amp;apos;level 2&amp;apos;:&amp;#123;0:&amp;apos;leaf node&amp;apos;,1:&amp;apos;leaf node&amp;apos;&amp;#125;&amp;#125;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tp.createPlot(myTree)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习中常常会用到大量的数据表，对数据进行可视化有助于对数据进行分析，这里主要介绍几种常用的数据可视化方向，包括表等线性结构、图等网络结构的可视化方法。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Windows下安装Python的机器学习（Scikit-Learn）算法库方法</title>
    <link href="http://WustChuiChui.github.io/2016/04/09/built-scikit-learn/"/>
    <id>http://WustChuiChui.github.io/2016/04/09/built-scikit-learn/</id>
    <published>2016-04-09T10:54:07.000Z</published>
    <updated>2016-04-09T14:20:03.548Z</updated>
    
    <content type="html">&lt;p&gt;Python社区仿照MATLAB开发了类似的数学分析库，主要包括用NumPy和SciPy来处理数据，用Matplotlib实现数据可视化。大多数Python数学和算法领域的应用广泛地将其作为基本的程序库。为了适应处理大规模数据的需求，Python在此基础上开发了Scikit-Learn机器学习算法库，同时还提供了深度学习算法库Theano,并支持GPU运算，Python已经可以完整地提供基于C/C++语言的机器学习开发包，而且都是开源的。本文主要介绍一下Scikit-Learn机器学习算法库的安装方法。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;Windows下安装Python的机器学习（Scikit-Learn）算法库方法&quot;&gt;&lt;a href=&quot;#Windows下安装Python的机器学习（Scikit-Learn）算法库方法&quot; class=&quot;headerlink&quot; title=&quot;Windows下安装Python的机器学习（Scikit-Learn）算法库方法&quot;&gt;&lt;/a&gt;Windows下安装Python的机器学习（Scikit-Learn）算法库方法&lt;/h1&gt;&lt;h2 id=&quot;一、基本环境&quot;&gt;&lt;a href=&quot;#一、基本环境&quot; class=&quot;headerlink&quot; title=&quot;一、基本环境&quot;&gt;&lt;/a&gt;一、基本环境&lt;/h2&gt;&lt;p&gt;操作系统：Windows 10   64位&lt;br&gt;Python版本：Pyhton 2.7&lt;br&gt;算法库：scikit-learn 0.16.1&lt;/p&gt;
&lt;h2 id=&quot;二、基本步骤&quot;&gt;&lt;a href=&quot;#二、基本步骤&quot; class=&quot;headerlink&quot; title=&quot;二、基本步骤&quot;&gt;&lt;/a&gt;二、基本步骤&lt;/h2&gt;&lt;h3 id=&quot;1-搭建Python开发环境&quot;&gt;&lt;a href=&quot;#1-搭建Python开发环境&quot; class=&quot;headerlink&quot; title=&quot;1.搭建Python开发环境&quot;&gt;&lt;/a&gt;1.搭建Python开发环境&lt;/h3&gt;&lt;p&gt;Python开发环境可以搭建在Linux下，也可以搭建在Windows下：这里在Windows 10环境下部署64位的Python开发环境。&lt;br&gt;Pyhton可在官方网站直接下载，网站为&amp;gt;&lt;a href=&quot;https://www.python.org/downloads/source/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.python.org/downloads/source/&lt;/a&gt;.&lt;br&gt;双击下载的安装程序，选择安装路径，也可以自己新建路径（尽量避免使用中文路径），这里我的路径是E:\python27,按照安装向导完成安装即可。&lt;/p&gt;
&lt;h3 id=&quot;2-安装Pyhton算法库&quot;&gt;&lt;a href=&quot;#2-安装Pyhton算法库&quot; class=&quot;headerlink&quot; title=&quot;2.安装Pyhton算法库&quot;&gt;&lt;/a&gt;2.安装Pyhton算法库&lt;/h3&gt;&lt;p&gt;这里以Scikit-Learn库为例，介绍一下Python算法库的安装方法。&lt;br&gt;cikit-Learn算法库可以在官方下载（&amp;gt;&lt;a href=&quot;http://scikit-learn.org/stable/），&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://scikit-learn.org/stable/），&lt;/a&gt;&lt;br&gt;也可以在翻墙去google上搜索相关资源，这里提供一个可以直接下载0.16.1版本Scikit-Learn库的链接（&amp;gt;&lt;a href=&quot;https://sourceforge.net/projects/scikit-learn/?source=typ_redirect）&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://sourceforge.net/projects/scikit-learn/?source=typ_redirect）&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;除此之外，Python还提供了大量的常用程序库，如数据库 API（MysqlDB）、GUI图形界面库(WxPython)、高并发协成库(gevent)、中文分词库（jieba）等外部库。这些库可以在下面的链接下载：&lt;br&gt;官方下载网址：&amp;gt;&lt;a href=&quot;https://pypi.python.org/pypi&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pypi.python.org/pypi&lt;/a&gt;&lt;br&gt;非官方下载网址：&amp;gt;http:/www.lfd.uci.edu/~gohlke/pythonlibs&lt;/p&gt;
&lt;p&gt;在安装Scikit-Learn库之前，请先装一个setuptools或者easy_install.&lt;br&gt;装好之后执行C:\Python27\Scripts\pip install 库名   命令即可&lt;/p&gt;
&lt;p&gt;这里的算法库的安装顺序为：NumPy-&amp;gt;SciPy-&amp;gt;Matplotlib-&amp;gt;Scikit-Learn&lt;/p&gt;
&lt;h2 id=&quot;三、其他工具&quot;&gt;&lt;a href=&quot;#三、其他工具&quot; class=&quot;headerlink&quot; title=&quot;三、其他工具&quot;&gt;&lt;/a&gt;三、其他工具&lt;/h2&gt;&lt;p&gt;WinPython：PythonWin 是一个 Python 集成开发环境，在许多方面都比 IDE 优秀。它集成了Scikit-Learn库和深度学习Theano库。集成了Spyder编辑器等开发工具，可对Python脚本进行编译和调试，支持语法高亮和单步跟踪，非常适合新手使用。（在师兄的指导下，本人目前也主要使用该工具）&lt;br&gt;Anaconda：Anaconda和WinPython类似，不过它是在Linux环境下集成的，比较适合Linux下的Python开发&lt;/p&gt;
&lt;h2 id=&quot;四、测试&quot;&gt;&lt;a href=&quot;#四、测试&quot; class=&quot;headerlink&quot; title=&quot;四、测试&quot;&gt;&lt;/a&gt;四、测试&lt;/h2&gt;&lt;p&gt; import numpy as np    #导入Numpy库&lt;br&gt; from numpy import *   #导入Numpy库&lt;br&gt; import matplotlib.pyplot as plt #导入Matplotlib库&lt;/p&gt;
&lt;p&gt; dataSet=[[1,2],[1,3],[2,2.5],[3,4],[3,6],[4,5],[6,9],[8,12],[10,15]]&lt;br&gt; dataMat=mat(dataSet).T              #将数据集转换为NumPy矩阵，并转置&lt;br&gt; plt.scatter(dataMat[0],dataMat[1],c=’red’,marker=’o’)    #绘制散点图&lt;/p&gt;
&lt;p&gt; #绘制直线图像&lt;br&gt; X=np.linspace(-2,12,100)  #产生直线数据集&lt;br&gt; Y=2*X+5&lt;br&gt; plt.plot(X,Y)            #绘制直线图&lt;br&gt; plt.show()&lt;/p&gt;
&lt;p&gt; 结果为：&lt;br&gt; &lt;img src=&quot;http://ww2.sinaimg.cn/large/006qSkuxjw1f2qss931j4j30bx07l0sv.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt; 上面这个是测试Numpy库的，要测试Scikit-Learn的安装，写个小程序看下对应的库能不能导入即可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Python社区仿照MATLAB开发了类似的数学分析库，主要包括用NumPy和SciPy来处理数据，用Matplotlib实现数据可视化。大多数Python数学和算法领域的应用广泛地将其作为基本的程序库。为了适应处理大规模数据的需求，Python在此基础上开发了Scikit-Learn机器学习算法库，同时还提供了深度学习算法库Theano,并支持GPU运算，Python已经可以完整地提供基于C/C++语言的机器学习开发包，而且都是开源的。本文主要介绍一下Scikit-Learn机器学习算法库的安装方法。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>计算机视觉 特征提取之HOG特征</title>
    <link href="http://WustChuiChui.github.io/2016/04/08/hog/"/>
    <id>http://WustChuiChui.github.io/2016/04/08/hog/</id>
    <published>2016-04-08T14:06:35.000Z</published>
    <updated>2016-04-08T14:43:48.343Z</updated>
    
    <content type="html">&lt;p&gt;方向梯度直方图（Histogram of Oriented Gradient, HOG）特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;计算机视觉-特征提取之HOG特征&quot;&gt;&lt;a href=&quot;#计算机视觉-特征提取之HOG特征&quot; class=&quot;headerlink&quot; title=&quot;计算机视觉 特征提取之HOG特征&quot;&gt;&lt;/a&gt;计算机视觉 特征提取之HOG特征&lt;/h1&gt;&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;HOG即histogram of oriented gradient, 是用于目标检测的特征描述子，该技术将图像局部出现的方向梯度次数进行计数，该方法和边缘方向直方图、scale-invariant feature transform类似，不同的是hog的计算基于一致空间的密度矩阵来提高准确率。&lt;/p&gt;
&lt;h2 id=&quot;算法流程&quot;&gt;&lt;a href=&quot;#算法流程&quot; class=&quot;headerlink&quot; title=&quot;算法流程&quot;&gt;&lt;/a&gt;算法流程&lt;/h2&gt;&lt;p&gt;1）灰度化图像；&lt;br&gt;2）采用Gamma校正法对输入图像进行颜色空间的归一化；调节图像的对比度，降低图像局部的阴影和光照变化所造成的影响，同时可以抑制噪音的干扰；&lt;br&gt;3）计算图像每个像素的梯度（大小和方向）；主要为了捕捉轮廓信息，同时进一步弱化光照的干扰；&lt;br&gt;4）强图像划分为小cells;&lt;br&gt;5)统计每个cell的梯度直方图，形成每个cell的descriptor;&lt;br&gt;6）强没几个cell组成一个block,一个block内所有的cell的特征descriptor串联起来得到该HOG特征；&lt;br&gt;7）将图像image内的所有block的HOG特征descriptor串联起来可以得到该图像image的HOG特征descriptor,即最终可供分类使用的特征向量。&lt;/p&gt;
&lt;p&gt;通俗的讲：HOG特征提取方法就是将image:&lt;br&gt;进行灰度化，划分为小cells，计算每个cell中每个像素的orientation,最后统计每个cell的梯度直方图，再串联起来得到图像的descriptor.&lt;/p&gt;
&lt;h2 id=&quot;HOG特征的特点&quot;&gt;&lt;a href=&quot;#HOG特征的特点&quot; class=&quot;headerlink&quot; title=&quot;HOG特征的特点&quot;&gt;&lt;/a&gt;HOG特征的特点&lt;/h2&gt;&lt;p&gt;1）HOG没有选取主方向，也没有旋转梯度直方图，因而本身不具有旋转不变性；&lt;br&gt;2）HOG本身不具有scale不变性，其scale不变性是通过改变检测图像的size来实现的；&lt;br&gt;3）HOG是在dense采样的图像块中求取的，在计算得到的HOG特征向量中隐含了该块与检测窗口的空间位置关系&lt;/p&gt;
&lt;h2 id=&quot;HOG特征的优点&quot;&gt;&lt;a href=&quot;#HOG特征的优点&quot; class=&quot;headerlink&quot; title=&quot;HOG特征的优点&quot;&gt;&lt;/a&gt;HOG特征的优点&lt;/h2&gt;&lt;p&gt;1)能够有效地描述图像区域的local shape的特征信息&lt;br&gt;2)采用“cell”方式进行梯度方向量化，使得特征描述算子具有一些（a small amount of）平移或旋转不变性&lt;br&gt;3)具有光照不变性&lt;/p&gt;
&lt;h2 id=&quot;影响HOG性能的主要因素&quot;&gt;&lt;a href=&quot;#影响HOG性能的主要因素&quot; class=&quot;headerlink&quot; title=&quot;影响HOG性能的主要因素&quot;&gt;&lt;/a&gt;影响HOG性能的主要因素&lt;/h2&gt;&lt;p&gt;finescale梯度、&lt;br&gt;精细定位面元、&lt;br&gt;相对粗空间装箱和高质量的地方对比正常话重叠块描述符等&lt;/p&gt;
&lt;h2 id=&quot;相关疑问&quot;&gt;&lt;a href=&quot;#相关疑问&quot; class=&quot;headerlink&quot; title=&quot;相关疑问&quot;&gt;&lt;/a&gt;相关疑问&lt;/h2&gt;&lt;p&gt;1）Q:为何使用方向直方图？&lt;br&gt;A:捕捉局部的形态信息&lt;br&gt;2）Q:为何使用cell?&lt;br&gt;A:实现小范围内的空间不变性&lt;/p&gt;
&lt;p&gt;##参考文献&lt;br&gt;“Histograms of Oriented Gradients for Human Detection”&lt;br&gt;“Finding People in Images and Videos” (PhD Thesis) &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;方向梯度直方图（Histogram of Oriented Gradient, HOG）特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Python学习与机器学习   各类距离与Python的具体实现</title>
    <link href="http://WustChuiChui.github.io/2016/04/08/mapython-distance/"/>
    <id>http://WustChuiChui.github.io/2016/04/08/mapython-distance/</id>
    <published>2016-04-08T11:50:15.000Z</published>
    <updated>2016-04-08T14:51:50.946Z</updated>
    
    <content type="html">&lt;p&gt;两个向量之间的距离（此时向量作为n维向量坐标系中的点）计算，在数学上称为向量的距离（Distance），也称为样本之间的相似性度量（Similarity Measurement）。它反映为某类事物在距离上接近或远离的程度。直觉上，距离越近，越容易归为一类；距离越远就越不同。划分的依据，称为距离。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;Python学习与机器学习-各类距离与Python的具体实现&quot;&gt;&lt;a href=&quot;#Python学习与机器学习-各类距离与Python的具体实现&quot; class=&quot;headerlink&quot; title=&quot;Python学习与机器学习   各类距离与Python的具体实现&quot;&gt;&lt;/a&gt;Python学习与机器学习   各类距离与Python的具体实现&lt;/h1&gt;&lt;h2 id=&quot;范数（数学基础）&quot;&gt;&lt;a href=&quot;#范数（数学基础）&quot; class=&quot;headerlink&quot; title=&quot;范数（数学基础）&quot;&gt;&lt;/a&gt;范数（数学基础）&lt;/h2&gt;&lt;p&gt;向量的范数可以简单、形象地理解为向量的长度，或者向量到坐标系原点的距离，或者相应空间内的两点之间的距离。&lt;br&gt;&lt;strong&gt; 向量的范数定义：&lt;/strong&gt; 向量的范数是一个函数||x||,满足非负性||x||&amp;gt;0,齐次性||cx||=|c|*||x||,三角不等式||x+y||&amp;lt;=||x||+||y||.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; L1范数： &lt;/strong&gt; ||x||为x向量各个元素绝对值之和。&lt;br&gt;&lt;strong&gt; L2范数： &lt;/strong&gt; ||x||为x向量各个元素平方和的开方，L2范数又称欧几里得范数。&lt;br&gt;&lt;strong&gt; Lp范数： &lt;/strong&gt; ||x||为x向量各个元素绝对值的p次方和的1/p次方。&lt;br&gt;&lt;strong&gt; L无穷范数： &lt;/strong&gt; ||x||为x向量各个元素绝对值最大的那个元素。&lt;/p&gt;
&lt;h2 id=&quot;各类距离的意义与Pyhon实现&quot;&gt;&lt;a href=&quot;#各类距离的意义与Pyhon实现&quot; class=&quot;headerlink&quot; title=&quot;各类距离的意义与Pyhon实现&quot;&gt;&lt;/a&gt;各类距离的意义与Pyhon实现&lt;/h2&gt;&lt;p&gt;这里介绍的几种距离公式如下：&lt;/p&gt;
&lt;p&gt;闵可夫斯基距离 (Minkowski Distance)&lt;br&gt;欧式距离 （Euclidean Distance）&lt;br&gt;曼哈顿距离 （Manhattan Distance）&lt;br&gt;切比雪夫距离 (Chebyshew Distance)&lt;br&gt;夹角余弦 (Cosine)&lt;br&gt;汉明距离 (Hamming Distance)&lt;br&gt;杰卡德相似系数 (Jaccard Similarity Coefficient)&lt;/p&gt;
&lt;h3 id=&quot;1-闵可夫斯基距离-Minkowski-Distance&quot;&gt;&lt;a href=&quot;#1-闵可夫斯基距离-Minkowski-Distance&quot; class=&quot;headerlink&quot; title=&quot;1.闵可夫斯基距离 (Minkowski Distance)&quot;&gt;&lt;/a&gt;1.闵可夫斯基距离 (Minkowski Distance)&lt;/h3&gt;&lt;p&gt;严格意义上讲，闵可夫斯基距离不能算是一种距离，而是一组距离的定义。&lt;br&gt;设有两个n维向量A(x1,x2,x3,….xn)和B(y1,y2,y3,….yn)间的闵可夫斯基距离定义为：&lt;br&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/006qSkuxgw1f2pkdwrt67j307t02sjrd.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中p是一个参数。&lt;br&gt;当p=1时，就是曼哈顿距离；&lt;br&gt;当p=2时，就是欧式距离；&lt;br&gt;当p-&amp;gt;无穷时，就是切比雪夫距离。&lt;/p&gt;
&lt;h3 id=&quot;2-欧式距离-（Euclidean-Distance）&quot;&gt;&lt;a href=&quot;#2-欧式距离-（Euclidean-Distance）&quot; class=&quot;headerlink&quot; title=&quot;2.欧式距离 （Euclidean Distance）&quot;&gt;&lt;/a&gt;2.欧式距离 （Euclidean Distance）&lt;/h3&gt;&lt;p&gt;欧式距离（L2范数）是最易于理解的一种距离计算方法，源于欧式空间中两点间的距离公式。两个n维向量A(x1,x2,x3,…xn)和B(y1,y2,y3,…..yn)间的欧式距离：&lt;br&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/006qSkuxgw1f2pkn8v6g6j30f202pt8v.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Python实现欧式距离：&lt;br&gt;from numpy import *&lt;/p&gt;
&lt;p&gt;vector1=mat([1,2,3])&lt;br&gt;vector2=mat([4,5,6])&lt;/p&gt;
&lt;p&gt;print sqrt((vector1-vector2)*(vector1-vector2).T)&lt;/p&gt;
&lt;h3 id=&quot;3-曼哈顿距离-（Manhattan-Distance）&quot;&gt;&lt;a href=&quot;#3-曼哈顿距离-（Manhattan-Distance）&quot; class=&quot;headerlink&quot; title=&quot;3.曼哈顿距离 （Manhattan Distance）&quot;&gt;&lt;/a&gt;3.曼哈顿距离 （Manhattan Distance）&lt;/h3&gt;&lt;p&gt;曼哈顿距离也称城市街区距离（City Block Distance）,也就是L1范数。&lt;br&gt;二维平面两点A(x1,y1)和B(x2,y2)间的曼哈顿距离为：&lt;br&gt;d=|x2-x1|+|y2-y1|&lt;br&gt;两个n维向量A(x1,x2,x3,…xn)和B(y1,y2,y3,….yn)间的曼哈顿距离为：&lt;br&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/006qSkuxgw1f2pl14yya7j308h02eq2u.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Python实现曼哈顿距离：&lt;br&gt;from numpy import *&lt;br&gt;vector1=mat([1,2,3])&lt;br&gt;vector2=mat([4,5,6])&lt;br&gt;print sum(abs(vector1-vector2))&lt;/p&gt;
&lt;h3 id=&quot;4-切比雪夫距离-Chebyshew-Distance&quot;&gt;&lt;a href=&quot;#4-切比雪夫距离-Chebyshew-Distance&quot; class=&quot;headerlink&quot; title=&quot;4.切比雪夫距离 (Chebyshew Distance)&quot;&gt;&lt;/a&gt;4.切比雪夫距离 (Chebyshew Distance)&lt;/h3&gt;&lt;p&gt;国际象棋中，国王每走一步能够走到相邻的8个方格中的任意一个，那么国王从A(x1,y1)走到B(x2,y2)最少需要多少步？最少步数总是max(|x2-x1|,|y2-y1|)步。类似的距离度量方法叫做切比雪夫距离（L无穷范数）。&lt;/p&gt;
&lt;p&gt;n维向量A(x11,x12,x13,….x1n)和B(x21,x22,x23,….x2n)间的切比雪夫距离：&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxgw1f2plab1n78j308l01jjra.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;它的另一种等价形式为：&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxgw1f2plctowpuj309q023mx4.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Python实现切比雪夫距离：&lt;br&gt;from numpy import *&lt;/p&gt;
&lt;p&gt;vector1=mat([1,2,3])&lt;br&gt;vector2=mat([4,7,6])&lt;br&gt;print abs(vector1-vector2).max()&lt;/p&gt;
&lt;h3 id=&quot;5-夹角余弦-Cosine&quot;&gt;&lt;a href=&quot;#5-夹角余弦-Cosine&quot; class=&quot;headerlink&quot; title=&quot;5.夹角余弦 (Cosine)&quot;&gt;&lt;/a&gt;5.夹角余弦 (Cosine)&lt;/h3&gt;&lt;p&gt;几何中夹角余弦可用来衡量两个向量方向的差异，机器学习中用这一概念衡量样本向量之间的差异。&lt;br&gt;两个n维样本点A(x11,x12,x13,…x1n)与B(x21,x22,x23,…x2n)的夹角余弦：类似地，对于两个样本点A(x11,x12,x13,…x1n)与B(x21,x22,x23,…x2n),可以使用类似夹角余弦的概念来衡量他们间的相似程度。&lt;br&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxgw1f2plpmulqej306v02lt8m.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;即&lt;br&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/006qSkuxgw1f2plsqwdv6j30au04xt8w.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;python 实现向量夹角&lt;/p&gt;
&lt;p&gt;from numpy import *&lt;/p&gt;
&lt;p&gt;vector1=mat([1,2,3])&lt;br&gt;vector2=mat([4,7,6])&lt;/p&gt;
&lt;p&gt;cosV12=dot(vector1,vector2)/(linalg.norm(vector1)*linalg.norm(vector2))&lt;br&gt;print cosV12&lt;/p&gt;
&lt;h3 id=&quot;6-汉明距离-Hamming-Distance&quot;&gt;&lt;a href=&quot;#6-汉明距离-Hamming-Distance&quot; class=&quot;headerlink&quot; title=&quot;6.汉明距离 (Hamming Distance)&quot;&gt;&lt;/a&gt;6.汉明距离 (Hamming Distance)&lt;/h3&gt;&lt;p&gt;汉明距离的定义：两个登场字符串s1和s2之间的汉明距离定义为将其中一个变为另外一个所需要的最小替换次数。&lt;br&gt;应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）&lt;/p&gt;
&lt;p&gt;Python实现汉明距离&lt;/p&gt;
&lt;p&gt;from numpy import *&lt;br&gt;matV=mat([1,1,0,1,1,0,1],[1,0,1,0,1,0,1])&lt;br&gt;smstr=nonzero(matV[0]-matV[1])&lt;br&gt;print shape(smstr[0]) [1]&lt;/p&gt;
&lt;h3 id=&quot;7-杰卡德相似系数-Jaccard-Similarity-Coefficient&quot;&gt;&lt;a href=&quot;#7-杰卡德相似系数-Jaccard-Similarity-Coefficient&quot; class=&quot;headerlink&quot; title=&quot;7.杰卡德相似系数 (Jaccard Similarity Coefficient)&quot;&gt;&lt;/a&gt;7.杰卡德相似系数 (Jaccard Similarity Coefficient)&lt;/h3&gt;&lt;p&gt;两个集合A和B的交集元素在A、B的并集中所占的比率，称为两个集合的杰卡德相似系数。&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxgw1f2pmannfgzj309b02lwef.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;杰卡德相似系数是衡量两个集合相似度的一种指标。&lt;br&gt;杰卡德距离：与杰卡德相似系数相反的概念是杰卡德距离。&lt;br&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxgw1f2pme9e4b5j30fu02f74e.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Python实现杰卡德距离&lt;br&gt;from numpy import *&lt;br&gt;import scipy.spatial.distance as dist #导入Scipy距离公式&lt;br&gt;matV=mat([1,1,0,1,0,1,0,0,1],[0,1,0,1,0,1,0,1,0])&lt;br&gt;print “dist.jaccard:”,dist.pdist(matV,’jaccard’)&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;两个向量之间的距离（此时向量作为n维向量坐标系中的点）计算，在数学上称为向量的距离（Distance），也称为样本之间的相似性度量（Similarity Measurement）。它反映为某类事物在距离上接近或远离的程度。直觉上，距离越近，越容易归为一类；距离越远就越不同。划分的依据，称为距离。&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>强大的随机森林分类器</title>
    <link href="http://WustChuiChui.github.io/2016/04/06/Random-forest/"/>
    <id>http://WustChuiChui.github.io/2016/04/06/Random-forest/</id>
    <published>2016-04-06T14:42:16.000Z</published>
    <updated>2016-04-07T08:19:17.493Z</updated>
    
    <content type="html">&lt;p&gt;机器学习中，随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别输出的类别的众树而定，它有着许多的有点，能很好地处理多分类问题。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;基本算法&quot;&gt;&lt;a href=&quot;#基本算法&quot; class=&quot;headerlink&quot; title=&quot;基本算法&quot;&gt;&lt;/a&gt;基本算法&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;原始训练集为N，应用bootstrap法有放回的随机抽取k个新的自助样本集，并由构建k棵决策树。每次未被抽到的样本组成了k个袋外数据；&lt;/li&gt;
&lt;li&gt;设有M个变量，在每一棵树的每个节点处随机抽取m(m&amp;lt;M)个变量，从m中选择一个最具有分辨能力的变量，变量的阈值通过检查每一个分类点确定。&lt;/li&gt;
&lt;li&gt;每棵树最大限度的生长，不做任何修剪（普通的决策树算法需要剪枝）。&lt;/li&gt;
&lt;li&gt;将生成的多棵分类树组成随机森林，用随机森林分类器对新的数据进行判断与分类，其分类结果按决策树分类器的投票决定。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;优点&quot;&gt;&lt;a href=&quot;#优点&quot; class=&quot;headerlink&quot; title=&quot;优点&quot;&gt;&lt;/a&gt;优点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;对于很多种资料，它可以产生高准确度的分类器。&lt;/li&gt;
&lt;li&gt;它可以处理大量的输入变量。&lt;/li&gt;
&lt;li&gt;可以在决定类别时，评估变量的重要性。&lt;/li&gt;
&lt;li&gt;它包含一个好方法可以估计遗失的资料，并且，如果有很大一部分的资料遗失，仍可以维持准确度。&lt;/li&gt;
&lt;li&gt;它提供一个实验方法，可以去侦测variable interactions。&lt;/li&gt;
&lt;li&gt;对于不平衡的分类资料集来说，它可以平衡误差。&lt;/li&gt;
&lt;li&gt;它计算各例中的近亲度，对于数据挖掘、侦测偏离者（outlier）和将资料视觉化非常有用。&lt;/li&gt;
&lt;li&gt;它可以延伸应用在未标记的资料上，即使用非监督式聚类方法。也可以侦测偏离者和观看资料。&lt;/li&gt;
&lt;li&gt;学习过程速度很快。&lt;/li&gt;
&lt;li&gt;能够处理很高维度的数据，并且不用做特征选择。&lt;/li&gt;
&lt;li&gt;创建随机森林的时候，对generlization error使用的是无偏估计。&lt;/li&gt;
&lt;li&gt;容易扩展到并行方法&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;缺点&quot;&gt;&lt;a href=&quot;#缺点&quot; class=&quot;headerlink&quot; title=&quot;缺点&quot;&gt;&lt;/a&gt;缺点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;在某些噪音较大的分类或回归问题上会过拟合&lt;/li&gt;
&lt;li&gt;对于有不同级别的属性的数据，级别划分较多的属性会对随机森林产生更大的影响，也就是说随机森林在这种数据上产生的属性权值是不可信的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;简要描述&quot;&gt;&lt;a href=&quot;#简要描述&quot; class=&quot;headerlink&quot; title=&quot;简要描述&quot;&gt;&lt;/a&gt;简要描述&lt;/h2&gt;&lt;p&gt;随机森林，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵之间是没有关联的，在得到森林之后，当有一个新的输入样本进入的时候，让森林中的每一棵决策树分别进行判断，对其进行分类，最后预测为被选择的最多的那一类。&lt;br&gt;建立决策树的过程中，需要注意两点：采样与完全分裂。首先是两个随机采样的过程，random forest对输入的数据进行行列的采样；这里的采样，可能存在重复的样本。假设有N个样本，那么采样的样本也为N个，在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中选择m（m&amp;lt;M）个,之后就是对采样后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面所有的样本都指向同一个分类。&lt;strong&gt; 一般很多的决策树算法都有一个很重要的步骤-剪枝，这里不需要这样做，因为之前的两个随机采样的过程保证了随机性，就算不减枝，也不会出现over-fitting。 &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 需要注意的是： &lt;/strong&gt; 每一棵决策树相对是较弱的，但是将多棵决策树结合起来就十分强大。可以这样比喻随机森林算法：每一棵决策树就是一个精通某一个窄领域的专家（从M个feature中选择m个让每一棵决策树进行学习），这样在随机森林中就有很多个精通不同领域的专家，对一个新的输入数据，可以从不同的角度去分析，最终由各方面的专家进行投票，得到最终结果。&lt;/p&gt;
&lt;h2 id=&quot;分裂特征点的选择&quot;&gt;&lt;a href=&quot;#分裂特征点的选择&quot; class=&quot;headerlink&quot; title=&quot;分裂特征点的选择&quot;&gt;&lt;/a&gt;分裂特征点的选择&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;信息增益&lt;/li&gt;
&lt;li&gt;信息增益化&lt;/li&gt;
&lt;li&gt;基尼指数&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;over-fitting的解决思路（不针对随机森林）&quot;&gt;&lt;a href=&quot;#over-fitting的解决思路（不针对随机森林）&quot; class=&quot;headerlink&quot; title=&quot;over-fitting的解决思路（不针对随机森林）&quot;&gt;&lt;/a&gt;over-fitting的解决思路（不针对随机森林）&lt;/h2&gt;&lt;p&gt;over-fitting(过拟合)指的是这样的一种学习现象：Ein很小，Eout却很大。是机器学习中比较常见的一种问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 原因： &lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用过于复杂的模型；&lt;/li&gt;
&lt;li&gt;数据噪音；&lt;/li&gt;
&lt;li&gt;有限的训练集。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt; 解决思路： &lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;假设过于复杂（excessive dvc）-&amp;gt;建立相对简单的模型；&lt;/li&gt;
&lt;li&gt;随机噪音 -&amp;gt;数据清洗，将标签错误的数据纠正或者删除；&lt;/li&gt;
&lt;li&gt;数据规模太小 -&amp;gt;收集更多的数据，或“伪造”更多数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;相关工具箱&quot;&gt;&lt;a href=&quot;#相关工具箱&quot; class=&quot;headerlink&quot; title=&quot;相关工具箱&quot;&gt;&lt;/a&gt;相关工具箱&lt;/h2&gt;&lt;p&gt;由于技术相对比较成熟，网上有大量开源的工具箱，2014年我在做视网膜层分割的时候，下载的工具箱来源于CSDN,代码语言为C/C++,另外，MATLAB也集成了相关工具箱，也可以使用MEX调用C/C++函数，python作为一门比较适合机器学习开发研究的语言，也集成了相关工具箱，感兴趣的同学可以自行下载。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习中，随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别输出的类别的众树而定，它有着许多的有点，能很好地处理多分类问题。&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Twin SVM的数学求解方法</title>
    <link href="http://WustChuiChui.github.io/2016/04/06/solve-Twin-SVM/"/>
    <id>http://WustChuiChui.github.io/2016/04/06/solve-Twin-SVM/</id>
    <published>2016-04-06T14:42:16.000Z</published>
    <updated>2016-04-08T01:11:13.904Z</updated>
    
    <content type="html">&lt;p&gt;第一篇博客已经对Twin SVM做了简单的介绍，这里主要从数学的角度去分析Twin SVM的求解思路。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;一、基本思想&quot;&gt;&lt;a href=&quot;#一、基本思想&quot; class=&quot;headerlink&quot; title=&quot;一、基本思想&quot;&gt;&lt;/a&gt;一、基本思想&lt;/h2&gt;&lt;p&gt;首先构造两个超平面，一个正超平面和一个负超平面，使得正负超平面尽可能地分别接近所有正类点的输入和负类点的输入，然后以这两个超平面为基础，构造决策函数；输入x距离正超平面较负超平面近时，即推断为正类；否则推断为负类。&lt;/p&gt;
&lt;h2 id=&quot;二、数学描述&quot;&gt;&lt;a href=&quot;#二、数学描述&quot; class=&quot;headerlink&quot; title=&quot;二、数学描述&quot;&gt;&lt;/a&gt;二、数学描述&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxjw1f2oiyiajyqj30jy085dh6.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Twin SVM 要求正超平面尽可能地靠近正类点，并尽可能地远离负类点；而负超平面尽可能地靠近负类点，并尽可能地远离正类点。由此，两个超平面的原始问题为：&lt;br&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/006qSkuxjw1f2oj1vyvogj30m807lmxu.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;和&lt;br&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/006qSkuxjw1f2oj3yicixj30ll06hjrz.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中，di为惩罚参数，&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxjw1f2oj6kite7j30eq01ct8r.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;目标函数第一项的作用是使正平面尽可能接近正输入；第二项和两个约束条件是使正超平面离开负输入一个距离，尽可能把负输入排斥在限定负超平面的另一侧。&lt;br&gt;它们的对偶问题分别为&lt;br&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/006qSkuxjw1f2oj8jivd9j30fa08qdgj.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxjw1f2ojab77xnj30io06x74z.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006qSkuxjw1f2ojb6qjrjj30fd04rdg4.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;即得到Twin SVM的决策函数为&lt;br&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006qSkuxjw1f2ojc8e0rqj30ei028mx7.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;第一篇博客已经对Twin SVM做了简单的介绍，这里主要从数学的角度去分析Twin SVM的求解思路。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何利用Hexo在自己的博客中添加多说评论</title>
    <link href="http://WustChuiChui.github.io/2016/04/02/comments/"/>
    <id>http://WustChuiChui.github.io/2016/04/02/comments/</id>
    <published>2016-04-02T12:02:54.000Z</published>
    <updated>2016-04-02T12:50:01.014Z</updated>
    
    <content type="html">&lt;p&gt;利用github+hexo搭建自己的博客后，可以自定义搭建自己的博客，要为自己的博客添加留言功能，需要完成一下几部：&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;#一、注册自己的多说账号&lt;br&gt;在百度上搜索多说，创建自己的站点，得到一个多说的二级域名。&lt;/p&gt;
&lt;p&gt;#二、修改自己本地的配置文件&lt;br&gt;在自己的博客根目录下以文本编辑器打开_config.yml文件，添加duoshuo_shortname: 你在多说得到的二级域名。当然也可以在根目录下找到themes文件夹，选中你用的主题的配置文件_config.yml文件，将其中的duoshuo_shortname:的值赋为多说二级域名。&lt;/p&gt;
&lt;p&gt;接下来需要修改选用主题的部分js脚本内容，如果你使用的是默认的landscape主题，这时只需要修改：你的博客根目录\themes\landscape\layout_partial\article.ejs中的以下代码&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;% if (!index &amp;amp;&amp;amp; post.comments &amp;amp;&amp;amp; config.disqus_shortname)&amp;#123; %&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;section id=&amp;quot;comments&amp;quot;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;div id=&amp;quot;disqus_thread&amp;quot;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;noscript&amp;gt;Please enable JavaScript to view the &amp;lt;a href=&amp;quot;//disqus.com/?ref_noscript&amp;quot;&amp;gt;comments powered by Disqus.&amp;lt;/a&amp;gt;&amp;lt;/noscript&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;/div&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;/section&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;% &amp;#125; %&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;改为：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;% if (!index &amp;amp;&amp;amp; post.comments &amp;amp;&amp;amp; config.duoshuo_shortname)&amp;#123; %&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;section id=&amp;quot;comments&amp;quot;&amp;gt;     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;div id=&amp;quot;ds-thread&amp;quot; class=&amp;quot;ds-thread&amp;quot; data-thread-key=&amp;quot;&amp;lt;%= post.path %&amp;gt;&amp;quot; data-title=&amp;quot;&amp;lt;%= post.title %&amp;gt;&amp;quot; data-url=&amp;quot;&amp;lt;%= post.permalink %&amp;gt;&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;var duoshuoQuery = &amp;#123;short_name:&amp;quot;datoublog&amp;quot;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    (function() &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      var ds = document.createElement(&amp;apos;script&amp;apos;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     ds.type = &amp;apos;text/javascript&amp;apos;;ds.async = true;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     ds.src = (document.location.protocol == &amp;apos;https:&amp;apos; ? &amp;apos;https:&amp;apos; : &amp;apos;http:&amp;apos;) + &amp;apos;//static.duoshuo.com/embed.js&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     ds.charset = &amp;apos;UTF-8&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     (document.getElementsByTagName(&amp;apos;head&amp;apos;)[0] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      || document.getElementsByTagName(&amp;apos;body&amp;apos;)[0]).appendChild(ds);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;#125;)();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;lt;/script&amp;gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/section&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;lt;% &amp;#125; %&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果你使用的自定义主题，比如我使用的cyanstyle，需要直接在\themes\cyanstyle\layout_partial中article.ejs添加上面的部分代码。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;利用github+hexo搭建自己的博客后，可以自定义搭建自己的博客，要为自己的博客添加留言功能，需要完成一下几部：&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Twin SVM 简介</title>
    <link href="http://WustChuiChui.github.io/2016/04/01/Twin-SVM-introduction/"/>
    <id>http://WustChuiChui.github.io/2016/04/01/Twin-SVM-introduction/</id>
    <published>2016-04-01T10:37:11.000Z</published>
    <updated>2016-04-02T11:43:50.632Z</updated>
    
    <content type="html">&lt;p&gt;在写自己的第一篇博客之前，还是想先对我的导师刘小明教授表示感谢，感谢您让我有机会接触机器学习相关算法。研究Twin SVM 相关算法已经一年有余，相对于常用的SVM，Twin SVM 有着巨大的&lt;br&gt;优势，相关理论已经十分成熟，网上也有较多开源的工具箱。接下来，就让我简单地对Twin SVM做一下介绍。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;Twin-SVM-简介&quot;&gt;&lt;a href=&quot;#Twin-SVM-简介&quot; class=&quot;headerlink&quot; title=&quot;Twin SVM 简介&quot;&gt;&lt;/a&gt;Twin SVM 简介&lt;/h1&gt;&lt;h2 id=&quot;一、定义&quot;&gt;&lt;a href=&quot;#一、定义&quot; class=&quot;headerlink&quot; title=&quot;一、定义&quot;&gt;&lt;/a&gt;一、定义&lt;/h2&gt;&lt;p&gt;在介绍Twin SVM之前，先简要地介绍一下当前比较火的支持向量机(Support Vector Machine,简称SVM，它是建立在统计学习理论和最优化理论基础上的一种有效的解决分类问题的机器学习方法。双重支持向量机（Twin Support Vector Machine）是在SVM的基础上发展起来的，是利用最优化方法解决分类问题的新工具。其基本思想是构造两个非平行的超平面来代替标准的SVM的一个分划超平面，具有较好的泛化推广能力。&lt;/p&gt;
&lt;h2 id=&quot;二、起源&quot;&gt;&lt;a href=&quot;#二、起源&quot; class=&quot;headerlink&quot; title=&quot;二、起源&quot;&gt;&lt;/a&gt;二、起源&lt;/h2&gt;&lt;p&gt;SVM是由Vapnik等人提出的，在一定程度上克服了“过学习”和“维数灾难”等传统问题。它根据有限的样本信息在模型的复杂性和学习能力之间寻求最佳折衷。以求获得最好的推广能力。Twin SVM最初由Jayadeva等人于2007年针对二分类问题提出的。Twin SVM较传统的SVM运算速度更快，对大规模数据具有更好的处理能力；同时，Twin SVM 利用最大间隔思想将SVM构造的平行平面推广到更广泛的非平行平面。在大数据时代，Twin SVM 的优势会越来越明显（对比于SVM）。&lt;/p&gt;
&lt;h2 id=&quot;三、基本思想&quot;&gt;&lt;a href=&quot;#三、基本思想&quot; class=&quot;headerlink&quot; title=&quot;三、基本思想&quot;&gt;&lt;/a&gt;三、基本思想&lt;/h2&gt;&lt;p&gt;首先构造两个超平面，一个正超平面和一个负超平面，使得正负超平面尽可能地分别接近所有正类点的输入和负类点的输入，然后以这两个超平面为基础，构造决策函数；输入x距离正超平面较负超平面近时，即推断为正类；否则推断为负类。&lt;/p&gt;
&lt;h2 id=&quot;四、优势&quot;&gt;&lt;a href=&quot;#四、优势&quot; class=&quot;headerlink&quot; title=&quot;四、优势&quot;&gt;&lt;/a&gt;四、优势&lt;/h2&gt;&lt;p&gt;不同于传统的SVM基于最大间隔原则求得一个超平面从而得到决策函数，Twin SVM 需要构造两个较小的凸二次优化问题，极大地减少了训练时间；&lt;br&gt;Twin SVM较传统的SVM运算速度更快，对大规模数据具有更好的处理能力；&lt;br&gt;同时具有良好的泛化能力。&lt;/p&gt;
&lt;h2 id=&quot;五、核心要素&quot;&gt;&lt;a href=&quot;#五、核心要素&quot; class=&quot;headerlink&quot; title=&quot;五、核心要素&quot;&gt;&lt;/a&gt;五、核心要素&lt;/h2&gt;&lt;p&gt;同SVM类似，Twin SVM的三个核心的要素是：最大间隔原则，对偶理论，核函数。其中，最关键在于核函数：低维空间向量通常难以划分，解决的办法是将它们映射到高维空间，但这个办法带来的困难是计算复杂度的增加，而核函数正好巧妙地解决了这个问题；&lt;strong&gt; 即：只要选用了适当的核函数，就可以得到高维空间的分类函数。 &lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;六、数学描述&quot;&gt;&lt;a href=&quot;#六、数学描述&quot; class=&quot;headerlink&quot; title=&quot;六、数学描述&quot;&gt;&lt;/a&gt;六、数学描述&lt;/h2&gt;&lt;p&gt;设训练集为T={(x1,+1),….,(xp,+1),(X(p+1),-1),…(x(p+q),-1)},其中,x(i)∈𝑅^𝑛,i=1,…p+q。分类问题就是根据给定的训练集分别求得一对不平行的拟合超平面w*x+b=0(正负超平面分别对应一组w,b的值)。最终根据得到一组非平行的超平面对新的样本进行分类。&lt;/p&gt;
&lt;p&gt;第一篇就介绍这么多啦，相对比较基础，后续会继续介绍相关Twin求解方法和实际应用，希望对大家有所帮助。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在写自己的第一篇博客之前，还是想先对我的导师刘小明教授表示感谢，感谢您让我有机会接触机器学习相关算法。研究Twin SVM 相关算法已经一年有余，相对于常用的SVM，Twin SVM 有着巨大的&lt;br&gt;优势，相关理论已经十分成熟，网上也有较多开源的工具箱。接下来，就让我简单地对Twin SVM做一下介绍。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
